[{"title":"IO的理解和学习（未完善）","url":"/2022/04/26/IO/","content":"\n# I/O\n\n## 什么是I/O\n\n什么是I/O，这里你需要知道一个图 冯诺依曼结构体系\n\n计算机 输入设备 输出设备 控制器 运算器 和存储器![68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303139303632343132323132363339382e6a7065673f782d6f73732d70726f636573733d696d6167652f77617465726d61726b2c747970655f5a6d46755a33706f5a57356e6147567064476](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/68747470733a2f2f696d672d626c6f672e6373646e696d672e636e2f32303139303632343132323132363339382e6a7065673f782d6f73732d70726f636573733d696d6167652f77617465726d61726b2c747970655f5a6d46755a33706f5a57356e6147567064476.jpg)\n\nI/O就是描述了计算机系统与外部设备之间通信的过程\n\n再从应用程序上了解I/O\n\n首先为了保证操作系统的稳定性和安全性，一个进程的地址空间被划分为用户空间（User Space）和内核空间（Kernel Space）\n\n应用程序都是运行在用户空间上，而内核空间才能进行系统态级别的资源有关的操作，比如如文件管理、进程通信、内存管理等等。也就是说，我们想要进行 IO 操作，一定是要依赖内核空间的能力。\n\n我们也不能直接访问内核空间，需要通过发起系统调用，让操作系统来做\n\n（这里讲一下为了避免频繁的I/O操作，会存在缓冲区的概念,详情 见目录）：\n\n当应用程序发起 I/O 调用后，会经历两个步骤：\n\n1. 内核等待 I/O 设备准备好数据\n2. 内核将数据从内核空间拷贝到用户空间。\n\n## 内核缓冲与进程缓冲区\n\n缓冲区的目的，是为了减少频繁的系统IO调用。大家都知道，系统调用需要保存之前的进程数据和状态等信息，而结束调用之后回来还需要恢复之前的信息，为了减少这种损耗时间、也损耗性能的系统调用，于是出现了缓冲区。\n\n有了缓冲区，操作系统使用read函数把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区中。等待缓冲区达到一定数量的时候，再进行IO的调用，提升性能。至于什么时候读取和存储则由内核来决定，用户程序不需要关心。\n\n在linux系统中，系统内核也有个缓冲区叫做内核缓冲区。每个进程有自己独立的缓冲区，叫做进程缓冲区。\n\n所以，用户程序的IO读写程序，大多数情况下，并没有进行实际的IO操作，而是在读写自己的进程缓冲区。\n\n\n\n## java IO读写的底层流程\n\n用户程序进行IO的读写，基本上会用到系统调用read&write，read把数据从内核缓冲区复制到进程缓冲区，write把数据从进程缓冲区复制到内核缓冲区，它们不等价于数据在内核缓冲区和磁盘之间的交换。\n\n![20190105163657587](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/20190105163657587.png)\n\n首先看看一个典型Java 服务端处理网络请求的典型过程：\n\n（1）客户端请求\n\nLinux通过网卡，读取客户断的请求数据，将数据读取到内核缓冲区。\n\n（2）获取请求数据\n\n服务器从内核缓冲区读取数据到Java进程缓冲区。\n\n（1）服务器端业务处理\n\nJava服务端在自己的用户空间中，处理客户端的请求。\n\n（2）服务器端返回数据\n\nJava服务端已构建好的响应，从用户缓冲区写入系统缓冲区。\n\n（3）发送给客户端\n\nLinux内核通过网络 I/O ，将内核缓冲区中的数据，写入网卡，网卡通过底层的通讯协议，会将数据发送给目标客户端。\n\n\n\n## BIO\n\n在linux中的Java进程中，默认情况下所有的socket都是blocking IO。在阻塞式 I/O 模型中，应用程序在从IO系统调用开始，一直到到系统调用返回，这段时间是阻塞的。返回成功后，应用进程开始处理用户空间的缓存数据。\n\n[![在这里插入图片描述](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/20190105163801795.jpg)](https://img-blog.csdnimg.cn/20190105163801795.jpg)\n\n举个栗子，发起一个blocking socket的read读操作系统调用，流程大概是这样：\n\n（1）当用户线程调用了read系统调用，内核（kernel）就开始了IO的第一个阶段：准备数据。很多时候，数据在一开始还没有到达（比如，还没有收到一个完整的Socket数据包），这个时候kernel就要等待足够的数据到来。\n\n（2）当kernel一直等到数据准备好了，它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。\n\n（3）从开始IO读的read系统调用开始，用户线程就进入阻塞状态。一直到kernel返回结果后，用户线程才解除block的状态，重新运行起来。\n\n所以，blocking IO的特点就是在内核进行IO执行的两个阶段，用户线程都被block了。\n\nBIO的优点：\n\n程序简单，在阻塞等待数据期间，用户线程挂起。用户线程基本不会占用 CPU 资源。\n\nBIO的缺点：\n\n一般情况下，会为每个连接配套一条独立的线程，或者说一条线程维护一个连接成功的IO流的读写。在并发量小的情况下，这个没有什么问题。但是，当在高并发的场景下，需要大量的线程来维护大量的网络连接，内存、线程切换开销会非常巨大。因此，基本上，BIO模型在高并发场景下是不可用的。\n\n## NIO\n\n在linux系统下，可以通过设置socket使其变为non-blocking。NIO 模型中应用程序在一旦开始IO系统调用，会出现以下两种情况：\n\n（1）在内核缓冲区没有数据的情况下，系统调用会立即返回，返回一个调用失败的信息。\n\n（2）在内核缓冲区有数据的情况下，是阻塞的，直到数据从内核缓冲复制到用户进程缓冲。复制完成后，系统调用返回成功，应用进程开始处理用户空间的缓存数据。\n[![在这里插入图片描述](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/20190105163821398.jpg)](https://img-blog.csdnimg.cn/20190105163821398.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NyYXp5bWFrZXJjaXJjbGU=,size_16,color_FFFFFF,t_70)\n\n举个栗子。发起一个non-blocking socket的read读操作系统调用，流程是这个样子：\n\n（1）在内核数据没有准备好的阶段，用户线程发起IO请求时，立即返回。用户线程需要不断地发起IO系统调用。\n\n（2）内核数据到达后，用户线程发起系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。\n\n（3）用户线程才解除block的状态，重新运行起来。经过多次的尝试，用户线程终于真正读取到数据，继续执行。\n\nNIO的特点：\n\n应用程序的线程需要不断的进行 I/O 系统调用，轮询数据是否已经准备好，如果没有准备好，继续轮询，直到完成系统调用为止。\n\nNIO的优点：每次发起的 IO 系统调用，在内核的等待数据过程中可以立即返回。用户线程不会阻塞，实时性较好。\n\nNIO的缺点：需要不断的重复发起IO系统调用，这种不断的轮询，将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低。\n\n总之，NIO模型在高并发场景下，也是不可用的。一般 Web 服务器不使用这种 IO 模型。一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。java的实际开发中，也不会涉及这种IO模型。\n\n再次说明，Java NIO（New IO） 不是IO模型中的NIO模型，而是另外的一种模型，叫做IO多路复用模型（ IO multiplexing ）。\n\n## I/O多路复用\n\n就拿连接来看多路复用可以应用于多个连接下，因为他是基于select，epoll的系统调用的![20190105163846560](C:\\Users\\wcy\\Desktop\\学习笔记\\20190105163846560.jpg)系统调用\n\n而这里我想说连接的数据一般会通过网卡转入内核空间，select就像是一个监控，多个连接的状态下，谁的连接数据先在内核中准备好，就给用户空间一个响应，然后用户空间才开始read知道内核空间数据复制到了用户空间\n\n在这种模式中，首先不是进行read系统调动，而是进行select/epoll系统调用。当然，这里有一个前提，需要将目标网络连接，提前注册到select/epoll的可查询socket列表中。然后，才可以开启整个的IO多路复用模型的读流程。\n\n（1）进行select/epoll系统调用，查询可以读的连接。kernel会查询所有select的可查询socket列表，当任何一个socket中的数据准备好了，select就会返回。\n\n当用户进程调用了select，那么整个线程会被block（阻塞掉）。\n\n（2）用户线程获得了目标连接后，发起read系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。\n\n（3）用户线程才解除block的状态，用户线程终于真正读取到数据，继续执行。\n\n多路复用IO的特点：\n\nIO多路复用模型，建立在操作系统kernel内核能够提供的多路分离系统调用select/epoll基础之上的。多路复用IO需要用到两个系统调用（system call）， 一个select/epoll查询调用，一个是IO的读取调用。\n\n和NIO模型相似，多路复用IO需要轮询。负责select/epoll查询调用的线程，需要不断的进行select/epoll轮询，查找出可以进行IO操作的连接。\n\n另外，多路复用IO模型与前面的NIO模型，是有关系的。对于每一个可以查询的socket，一般都设置成为non-blocking模型。只是这一点，对于用户程序是透明的（不感知）。\n\n多路复用IO的优点：\n\n用select/epoll的优势在于，它可以同时处理成千上万个连接（connection）。与一条线程维护一个连接相比，I/O多路复用技术的最大优势是：系统不必创建线程，也不必维护这些线程，从而大大减小了系统的开销。\n\nJava的NIO（new IO）技术，使用的就是IO多路复用模型。在linux系统上，使用的是epoll系统调用。\n\n多路复用IO的缺点：\n\n本质上，select/epoll系统调用，属于同步IO，也是阻塞IO。都需要在读写事件就绪后，自己负责进行读写，也就是说这个读写过程是阻塞的。\n\n\n\n## 异步I/O（AIO）\n\n这是真正的非阻塞I/O，通过用户线程调用read系统调用，然后立刻返回去做其他事情，不阻塞\n\n而内核就开始数据准备工作，而数据就绪后就直接复制到用户空间，最后kernel会给用户线程发送一个信号（signal），或者回调用户线程注册的回调接口，告诉用户线程read操作完成了。用户线程读取用户缓冲区的数据，完成后续的业务操作。\n\n异步IO模型的特点：\n\n在内核kernel的等待数据和复制数据的两个阶段，用户线程都不是block(阻塞)的。用户线程需要接受kernel的IO操作完成的事件，或者说注册IO操作完成的回调函数，到操作系统的内核。所以说，异步IO有的时候，也叫做信号驱动 IO 。\n\n异步IO模型缺点：\n\n需要完成事件的注册与传递，这里边需要底层操作系统提供大量的支持，去做大量的工作。\n\n目前来说， Windows 系统下通过 IOCP 实现了真正的异步 I/O。但是，就目前的业界形式来说，Windows 系统，很少作为百万级以上或者说高并发应用的服务器操作系统来使用。\n\n而在 Linux 系统下，异步IO模型在2.6版本才引入，目前并不完善。所以，这也是在 Linux 下，实现高并发网络编程时都是以 IO 复用模型模式为主。\n\n\n\n这里我要补充以一下这个体系里面比较抽象的概念 就是信息的传递，尤其是那几张图所表达的东西。\n\n我们一般是通过socket来进行一些信息的的传递，而socket又是与在物理上与网卡打交道，也就是说你的程序处理socket，读操作时，其实就是启动了系统调用read，这个时候socket连接在网卡中的数据就开始传递数据到内核空间，这就是所谓的数据准备，然后再由内核空间复制到用户空间。\n\n而这里面IO多路复用的意思我大概理解一下就是说，同一时间有多个socket连接的情况下，大家都在由网卡向内核缓冲区传递数据（多个数据准备同时进行），而程序就需要不断地轮询看哪个socket传递得快，先完成数据准备的连接就可以优先进行数据复制。也就是说和NIO一样有一个轮询操作，而正是因为有这个轮询（补充一个概念：单个select 以及read 下 它是阻塞的，但是不满足它会立即返回）才有更多的操作空间，因为轮询是有间隔的，虽然每次的单个调用是阻塞的但是，每次轮询间隔就可以空出来，不像BIO，在没返回数据准备就绪之前一直阻塞的情况","tags":["IO"],"categories":["计算机组成原理"]},{"title":"Spring","url":"/2022/03/27/Spring/","content":"\n# Spring![Spring的各个组件](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d362f537072696e672545342542382542422545382541362538312545362541382541312545352539442539372e706e67.png)\n\n具体文章可以看知乎上的这篇文章 [(41 封私信 / 80 条消息) Spring IoC有什么好处呢？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/23277575/answer/169698662)\n\n## IOC\n\n要了解**控制反转( Inversion of Control )**, 我觉得有必要先了解软件设计的一个重要思想：**依赖倒置原则（Dependency Inversion Principle ）**。\n\n\n\n**什么是依赖倒置原则？**假设我们设计一辆汽车：先设计轮子，然后根据轮子大小设计底盘，接着根据底盘设计车身，最后根据车身设计好整个汽车。这里就出现了一个“依赖”关系：汽车依赖车身，车身依赖底盘，底盘依赖轮子。\n\n![img](https://pic2.zhimg.com/50/v2-c68248bb5d9b4d64d22600571e996446_hd.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-c68248bb5d9b4d64d22600571e996446_720w.jpg?source=1940ef5c)\n\n这样的设计看起来没问题，但是可维护性却很低。假设设计完工之后，上司却突然说根据市场需求的变动，要我们把车子的轮子设计都改大一码。这下我们就蛋疼了：因为我们是根据轮子的尺寸设计的底盘，轮子的尺寸一改，底盘的设计就得修改；同样因为我们是根据底盘设计的车身，那么车身也得改，同理汽车设计也得改——整个设计几乎都得改！\n\n我们现在换一种思路。我们先设计汽车的大概样子，然后根据汽车的样子来设计车身，根据车身来设计底盘，最后根据底盘来设计轮子。这时候，依赖关系就倒置过来了：轮子依赖底盘， 底盘依赖车身， 车身依赖汽车。\n\n![img](https://pic4.zhimg.com/50/v2-e64bf72c5c04412f626b21753aa9e1a1_hd.jpg?source=1940ef5c)![img](https://pic4.zhimg.com/80/v2-e64bf72c5c04412f626b21753aa9e1a1_720w.jpg?source=1940ef5c)\n\n这时候，上司再说要改动轮子的设计，我们就只需要改动轮子的设计，而不需要动底盘，车身，汽车的设计了。\n\n这就是依赖倒置原则——把原本的高层建筑依赖底层建筑“倒置”过来，变成底层建筑依赖高层建筑。高层建筑决定需要什么，底层去实现这样的需求，但是高层并不用管底层是怎么实现的。这样就不会出现前面的“牵一发动全身”的情况。\n\n\n\n**控制反转（Inversion of Control）** 就是依赖倒置原则的一种代码设计的思路。具体采用的方法就是所谓的**依赖注入（Dependency Injection）**。其实这些概念初次接触都会感到云里雾里的。说穿了，这几种概念的关系大概如下：\n\n![img](https://pic2.zhimg.com/50/v2-ee924f8693cff51785ad6637ac5b21c1_hd.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-ee924f8693cff51785ad6637ac5b21c1_720w.jpg?source=1940ef5c)\n\n为了理解这几个概念，我们还是用上面汽车的例子。只不过这次换成代码。我们先定义四个Class，车，车身，底盘，轮胎。然后初始化这辆车，最后跑这辆车。代码结构如下：\n\n![img](https://pic2.zhimg.com/80/v2-8ec294de7d0f9013788e3fb5c76069ef_720w.jpg?source=1940ef5c)\n\n这样，就相当于上面第一个例子，上层建筑依赖下层建筑——每一个类的构造函数都直接调用了底层代码的构造函数。假设我们需要改动一下轮胎（Tire）类，把它的尺寸变成动态的，而不是一直都是30。我们需要这样改：\n\n![img](https://pic2.zhimg.com/50/v2-64e8b19eeb70d9cf87c27fe4c5c0fc81_hd.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-64e8b19eeb70d9cf87c27fe4c5c0fc81_720w.jpg?source=1940ef5c)\n\n由于我们修改了轮胎的定义，为了让整个程序正常运行，我们需要做以下改动：\n\n![img](https://pic4.zhimg.com/50/v2-82e0c12a1b26f7979ed9241e169affda_hd.jpg?source=1940ef5c)![img](https://pic4.zhimg.com/80/v2-82e0c12a1b26f7979ed9241e169affda_720w.jpg?source=1940ef5c)\n\n由此我们可以看到，仅仅是为了修改轮胎的构造函数，这种设计却需要**修改整个上层所有类的构造函数**！在软件工程中，**这样的设计几乎是不可维护的**——在实际工程项目中，有的类可能会是几千个类的底层，如果每次修改这个类，我们都要修改所有以它作为依赖的类，那软件的维护成本就太高了。\n\n所以我们需要进行控制反转（IoC），及上层控制下层，而不是下层控制着上层。我们用依赖注入（Dependency Injection）这种方式来实现控制反转。**所谓依赖注入，就是把底层类作为参数传入上层类，实现上层类对下层类的“控制**”。这里我们用**构造方法传递的依赖注入方式**重新写车类的定义：\n\n![img](https://pic2.zhimg.com/50/v2-c920a0540ce0651003a5326f6ef9891d_hd.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-c920a0540ce0651003a5326f6ef9891d_720w.jpg?source=1940ef5c)\n\n这里我们再把轮胎尺寸变成动态的，同样为了让整个系统顺利运行，我们需要做如下修改：\n\n![img](https://pic2.zhimg.com/50/v2-99ad2cd809fcb86dd791ff7f65fb1779_hd.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-99ad2cd809fcb86dd791ff7f65fb1779_720w.jpg?source=1940ef5c)\n\n看到没？这里**我只需要修改轮胎类就行了，不用修改其他任何上层类。**这显然是更容易维护的代码。不仅如此，在实际的工程中，这种设计模式还有利于**不同组的协同合作和单元测试：**比如开发这四个类的分别是四个不同的组，那么只要定义好了接口，四个不同的组可以同时进行开发而不相互受限制；而对于单元测试，如果我们要写Car类的单元测试，就只需要Mock一下Framework类传入Car就行了，而不用把Framework, Bottom, Tire全部new一遍再来构造Car。\n\n这里我们是采用的**构造函数传入**的方式进行的依赖注入。其实还有另外两种方法：**Setter传递**和**接口传递**。这里就不多讲了，核心思路都是一样的，都是为了实现**控制反转**。\n\n![img](https://pic4.zhimg.com/50/v2-861683acac47577c81f2b7493dd05649_hd.jpg?source=1940ef5c)![img](https://pic4.zhimg.com/80/v2-861683acac47577c81f2b7493dd05649_720w.jpg?source=1940ef5c)\n\n\n\n\n\n看到这里你应该能理解什么控制反转和依赖注入了。那什么是**控制反转容器(IoC Container)**呢？其实上面的例子中，对车类进行初始化的那段代码发生的地方，就是控制反转容器。\n\n![img](https://pic3.zhimg.com/50/v2-c845802f9187953ed576e0555f76da42_hd.jpg?source=1940ef5c)![img](https://pic3.zhimg.com/80/v2-c845802f9187953ed576e0555f76da42_720w.jpg?source=1940ef5c)\n\n显然你也应该观察到了，因为采用了依赖注入，在初始化的过程中就不可避免的会写大量的new。这里IoC容器就解决了这个问题。**这个容器可以自动对你的代码进行初始化，你只需要维护一个Configuration（可以是xml可以是一段代码），而不用每次初始化一辆车都要亲手去写那一大段初始化的代码**。这是引入IoC Container的第一个好处。\n\nIoC Container的第二个好处是：**我们在创建实例的时候不需要了解其中的细节。**在上面的例子中，我们自己手动创建一个车instance时候，是从底层往上层new的：\n\n![img](https://pic3.zhimg.com/50/v2-555b2be7d76e78511a6d6fed3304927f_hd.jpg?source=1940ef5c)![img](https://pic3.zhimg.com/80/v2-555b2be7d76e78511a6d6fed3304927f_720w.jpg?source=1940ef5c)\n\n这个过程中，我们需要了解整个Car/Framework/Bottom/Tire类构造函数是怎么定义的，才能一步一步new/注入。\n\n而IoC Container在进行这个工作的时候是反过来的，它先从最上层开始往下找依赖关系，到达最底层之后再往上一步一步new（有点像深度优先遍历）：\n\n![img](https://pic4.zhimg.com/50/v2-24a96669241e81439c636e83976ba152_hd.jpg?source=1940ef5c)![img](https://pic4.zhimg.com/80/v2-24a96669241e81439c636e83976ba152_720w.jpg?source=1940ef5c)\n\n这里IoC Container可以直接隐藏具体的创建实例的细节，在我们来看它就像一个工厂：\n\n![img](https://pic2.zhimg.com/50/v2-5ca61395f37cef73c7bbe7808f9ea219_hd.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-5ca61395f37cef73c7bbe7808f9ea219_720w.jpg?source=1940ef5c)\n\n我们就像是工厂的客户。我们只需要向工厂请求一个Car实例，然后它就给我们按照Config创建了一个Car实例。我们完全不用管这个Car实例是怎么一步一步被创建出来。\n\n实际项目中，有的Service Class可能是十年前写的，有几百个类作为它的底层。假设我们新写的一个API需要实例化这个Service，我们总不可能回头去搞清楚这几百个类的构造函数吧？IoC Container的这个特性就很完美的解决了这类问题——**因为这个架构要求你在写class的时候需要写相应的Config文件，所以你要初始化很久以前的Service类的时候，前人都已经写好了Config文件，你直接在需要用的地方注入这个Service就可以了**。这大大增加了项目的可维护性且降低了开发难度。\n\n总结与理解：什么是IOC呢？控制反转是一种思想，也是实现了依赖倒置原则的一种思想，这里我的理解可以拆开来看，控制/反转 首先控制指的是将对象交给IOC容器来管理，你无需考虑一个复杂的对象是如何创建的，同时容器也帮你维护了各个对象，你无需担心更多的问题。然后是反转，这涉及到依赖倒置原则，抽象不应该依赖于具体实现。具体还是要举例子来说明，就拿设计汽车来说，首先我们需要轮子然后是底盘和车身，也就是说汽车是依赖于车身，车身依赖于地盘而地盘有依赖于轮子（当然这里要讲讲依赖是指类中去创建对象）而这样的话如果你的轮子大小需求发生改变，你会发现变动会很大，（我去，好抽象，不知道怎么讲了）而如果说反转一下，也就是说车身依赖于汽车、地盘依赖于车身、轮胎依赖于地盘，就会出现不一样的东西，而这总反向的依赖关系需要注入来实现，构造器、setter、接口等注入方法，而这个注入的过程是由IOC容器来管理，用户是看不到的就像是一个工厂，当你需要Car，容器就给你一个，你并不清楚里面的具体情况，就像一个工厂，这里使用的就是类似于工厂模式。\n\n## aop\n\n面向切面编程\n\n## Spring的生命周期\n\n  ![生命周期](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/181454040628981.png)\n\n\n\n![生命周期](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d392d31372f353439363430372e6a7067.jpg)\n\n\n\n\n\n## Spring 框架中用到了哪些设计模式？\n\n- **工厂设计模式** : Spring使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。\n- **代理设计模式** : Spring AOP 功能的实现。\n- **单例设计模式** : Spring 中的 Bean 默认都是单例的。\n- **模板方法模式** : Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。\n- **包装器设计模式** : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。\n- **观察者模式:** Spring 事件驱动模型就是观察者模式很经典的一个应用。\n- **适配器模式** :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配`Controller`。\n- ......\n\n\n\n## Spring注入的方法（挺多的）\n\n### bean.xml注入\n\n#### 1.构造器注入 （空构造、含参构造）\n\n```\n    空构造注入\n    <bean id=\"person\" class=\"com.spring.demo.pojo.Person\"></bean>\n\n    其他构造注入\n    <bean id=\"person\" class=\"com.spring.demo.pojo.Person\">\n        <constructor-arg index=\"0\" value=\"test\"></constructor-arg>\n        <constructor-arg index=\"1\" value=\"1\"></constructor-arg>\n    </bean>\n    --------------------------------------------------\n    ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:bean.xml\");\n    Person pesson = (Person)context.getBean(\"person\");\n```\n\n#### 2.Setter（前提是要由set方法）\n\n​\t\n\n```\n\n    <bean id=\"person\" class=\"com.spring.demo.pojo.Person\">\n        <property name=\"name\" value=\"test\"></property>\n        <property name=\"num\" value=\"1\"></property>\n    </bean>\n    ---------------------------------------------------\n    ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:bean.xml\");\n    Person pesson = (Person)context.getBean(\"person\");\n    \n```\n\n#### 3.静态工厂方法注入\n\n```\n    \n    public class PersonStaticFactory {\n    \tpublic static Person getPerson(String name,String num){\n        \treturn new Person(name,num);\n    \t}\n\t}\n    ---------------------------------------------------\n    <bean id=\"personFactory\" class=\"com.spring.demo.factory.PersonStaticFactory\" factory-method=\"getPerson\">\n        <constructor-arg index=\"0\" value=\"test\"></constructor-arg>\n        <constructor-arg index=\"1\" value=\"1\"></constructor-arg>\n    </bean>\n    ----------------------------------------------------\n    \n    ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:bean.xml\");\n    Person pesson = (Person)context.getBean(\"personFactory\");\n```\n\n#### 4.实力工厂方法注入\n\n​\t这个和静态工厂的区别，首先他不是静态方法了。。\n\n```\n    public class PersonFactory {\n    \tpublic Person getPerson(String name,String num){\n        \treturn new Person(name,num);\n   \t \t}\n\t}\n    ----------------------------------------------------\n    <bean id=\"personFactory\" class=\"com.spring.demo.factory.PersonFactory\"></bean>\n    <bean id=\"person\" factory-bean=\"personFactory\" factory-method=\"getPerson\">\n        <constructor-arg index=\"0\" value=\"test\"></constructor-arg>\n        <constructor-arg index=\"1\" value=\"1\"></constructor-arg>\n    </bean>\n    \n    ----------------------------------------------------\n    ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:bean.xml\");\n    Person pesson = (Person)context.getBean(\"person\");\n```\n\n#### 5.FactoryBean注入（主要是工厂实现FactoryBean接口）\n\n```\npublic class PersonFactoryBean implements FactoryBean {\n    @Override\n    public Object getObject() throws Exception {\n        return new Person();\n    }\n\n    @Override\n    public Class<?> getObjectType() {\n        return Person.class;\n    }\n}\n------------------------------------------------\n<bean id=\"personFactoryBean\" class=\"com.spring.demo.factory.PersonFactoryBean\"></bean>\n\n------------------------------------------------\nClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:bean.xml\");\nPerson person = (Person)context.getBean(\"personFactoryBean\");\n```\n\n\n\n### 注解注入\n\n#### 1.@Component、@Controller 、@Service 、@Repository等注解可以定义bean\n\n其实后面三个都是基于@Component，不过业界的规矩就是\n\n​\tController一般用在控制层\n\n​\tService一般用在业务层\n\n​\tRepository一般用在数据层\n\n​\tComponent 一般是公共组件\n\n这里要注意的是如果你的这个注解用在了不和SpringBoot入口类同一级包下的话，需要配置注解扫描\n\n<context:component-scan base-package=\"\">\n\n在入口类上写上@CompoentScan(\"xxxx\")\n\n\n\n#### 2.JavaConfig\n\n```\n@Configuration\npublic class MyBeanConfiguration {\n    //@ConditionalOnXX 这个注解可以加限制\n    @Bean\n    public Person createPerson(){\n        return new Person();\n    }\n}\n```\n\n\n\n#### 3.Import注解\n\n```\n\n@Configuration\n@Import({Person.class, Role.class})\npublic class MyBeanConfig {\n}\n\n----------------------------------------\n    @Autowired\n    Person person;\n    @Autowired\n    Role role;\n```\n\n\n\n#### 4.ImportSelector(实现ImportSelector接口)\n\n```\npublic class DataImportSelector implements ImportSelector {\n    @Override\n    public String[] selectImports(AnnotationMetadata annotationMetadata) {\n        return new String[]{\n                \"com.spring.demo.pojo.Person\",\"com.spring.demo.pojo.Role\"\n        };\n    }\n}\n-----------------------------------------\n@Configuration\n@Import({DataImportSelector.class})\npublic class MyBeanConfig {\n}\n-----------------------------------------\n这个方法有问题，我不知道怎么找到。。。。\n```\n\n\n\n#### 5.ImportBeanDefinitionRegistrar(实现ImportBeanDefinitionRegistrar）\n\n```\npublic class PersonImportSelector implements ImportBeanDefinitionRegistrar {\n    @Override\n    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry, BeanNameGenerator importBeanNameGenerator) {\n        System.out.println(\"这里注入两个实例\");\n        RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Person.class);\n        registry.registerBeanDefinition(\"person\",rootBeanDefinition);\n\n        RootBeanDefinition rootBeanDefinition1 = new RootBeanDefinition(Role.class);\n        registry.registerBeanDefinition(\"role\",rootBeanDefinition1);\n    }\n}\n-------------------------------------------\n@Configuration\n@Import({PersonImportSelector.class})\npublic class MyBeanConfig {\n}\n   \n   \n--------------------------------------------\n   @Autowired\n    ApplicationContext context;//这里需要获取上下文\n    \n    Person person = (Person) context.getBean(\"person\");\n    \n    \n```\n\n\n\n#### 6.PostProcessor(后处理器---这让我联想到了Spring的生命周期，其中就有Bean和BeanFactory的后处理器参与)--------实现BeanDefinitionRegistryPostProcess\n\n```\n@Component\npublic class MyRegistryPostProcess implements BeanDefinitionRegistryPostProcessor {\n    @Override\n    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry beanDefinitionRegistry) throws BeansException {\n        System.out.println(\"自定义BeanDefinition后处理器\");\n        RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Person.class);\n        beanDefinitionRegistry.registerBeanDefinition(\"person\",rootBeanDefinition);\n\n        RootBeanDefinition rootBeanDefinition1 = new RootBeanDefinition(Role.class);\n        beanDefinitionRegistry.registerBeanDefinition(\"role\",rootBeanDefinition1);\n    }\n\n    @Override\n    public void postProcessBeanFactory(ConfigurableListableBeanFactory configurableListableBeanFactory) throws BeansException {\n\n    }\n}\n\n//这里你会发现还有一个方法postProcessBeanFactory 这也是父类BeanFactoryPostProcessor的一个方法，这里都可以注册bean\n区别在于\n\tBeanDefinitionRegistryPostProcessor更侧重于bean的注册\n\tBeanFactoryPostProcessor更侧重于对已经注册的bean的属性进行修改\n```\n\n\n\n\n\n# 扩展\n\nSpringMVC的核心是DispatcherServlet\n\n而这里涉及到一个抽象类 AbstarctAnnotationConfigDispatcherServletInitializer  当其部署到Servlet3.0容器中的时候，容器会自动发现它，并用它来配置Servlet上下文 它也会同时创建DispatcherServlet和ContextLoaderListener\n\n这里你要仔细观察 官方对于这个类方法中的解释\n\n一个创建了根应用上下文是由ContextLoaderListener提供\n\n一个创建了Servlet应用上下文是由DispatcherServlet提供\n\n\n\n```\nCreate the \"root\" application context to be provided to the ContextLoaderListener.\nThe returned context is delegated to ContextLoaderListener.ContextLoaderListener(WebApplicationContext) and will be established as the parent context for any DispatcherServlet application contexts. As such, it typically contains middle-tier services, data sources, etc.\nThis implementation creates an AnnotationConfigWebApplicationContext, providing it the annotated classes returned by getRootConfigClasses(). Returns null if getRootConfigClasses() returns null.\n\n\n@Override\n@Nullable\nprotected WebApplicationContext createRootApplicationContext() {\n   Class<?>[] configClasses = getRootConfigClasses();\n   if (!ObjectUtils.isEmpty(configClasses)) {\n      AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext();\n      context.register(configClasses);\n      return context;\n   }\n   else {\n      return null;\n   }\n}\n\n\nCreate a servlet application context to be provided to the DispatcherServlet.\nThe returned context is delegated to Spring's DispatcherServlet.DispatcherServlet(WebApplicationContext). As such, it typically contains controllers, view resolvers, locale resolvers, and other web-related beans.\nThis implementation creates an AnnotationConfigWebApplicationContext, providing it the annotated classes returned by getServletConfigClasses().\n\n@Override\nprotected WebApplicationContext createServletApplicationContext() {\n   AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext();\n   Class<?>[] configClasses = getServletConfigClasses();\n   if (!ObjectUtils.isEmpty(configClasses)) {\n      context.register(configClasses);\n   }\n   return context;\n}\n```\n\n\n\n当DispatcherServlet启动的时候，它会创建Spring应用上下文，并加载配置文件和配置类中所声明的bean\n\n我们希望DispatcherServlet加载包含Web组件的bean，如控制器、视图解析器以及处理映射，而ContextLoaderListener要加载应用中的其他bean。这些bean通常是驱动应用后端的中间件和数据层组件","tags":["Spring"],"categories":["编程","框架"]},{"title":"ElasticSearch(库、表、记录) - 入门","url":"/2022/03/20/ElasticSearch(库、表、记录) - 狂神篇入门/","content":"\n\n\n\n\n# ElasticSearch(库、表、记录) - 入门\n\n版本这里我使用的是7.6.2\n\n## 讲什么？\n\n1.创始人\n\n2.货比三家\n\n3.安装\n\n4.生态\n\n5.测试（分词器）\n\n6.RestFul操作 ES\n\n7.CRUD\n\n8.SpringBoot集成ElasticSearch\n\n9.爬虫爬取数据\n\n10.实战、模拟全文检索\n\n\n\n## Doug Cutting（这个人也搞了Hadoop）\n\n这个人一开始用java写了Lucene，目标是为各种中小型应用软件加入全文检索功能\n\n\n\n大数据就两个问题：存储加计算\n\n\n\n![image-20210901102154194](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901102154194.png)\n\n回到主题\n\nLucene是一套信息检索工具包（信息检索程序库）！jar包！（ES是对Lucene Api的封装）不包含搜索引擎\n\n包含的：索引结构、读写索引的工具、排序、搜索规则...工具类\n\n\n\nLucene和ElasticSearch关系：\n\nElasticSearch是基于Lucene做了一些封装和增强\n\n\n\n## ElasticSearch概述\n\nElaticSearch,简称es，es是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时地存储、检索数据；本身扩展性很好，可以扩展到上百台服务器、处理PB级别地数据。es也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索功能，它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单\n\n\n\n## ElasticSearch安装\n\n![image-20210901122752602](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901122752602.png)\n\n### 熟悉目录\n\n```\nbin 启动文件\nconfig 配置文件\n\tlog4j2 日志配置文件\n\tjvm.options JVM参数配置文件\n\telasticsearch.yml 配置文件 默认 9200端口\nlib 相关jar包\nlogs 日志\nmodules 功能模块\nplugins 插件\n```\n\n### 启动\n\n![image-20210901123357852](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901123357852.png)\n\n访问127.0.0.1:9200\n\n![image-20210901123428677](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901123428677.png)\n\n可视化界面\n\nhead插件\n\n下载这个前端项目 然后。。。\n\n![image-20210901124448947](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901124448947.png)\n\n![image-20210901124514069](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901124514069.png)\n\n![image-20210901124620497](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901124620497.png)\n\n这里连接不上会出现跨域问题\n\n![image-20210901124640733](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901124640733.png)\n\n在es的yml配置文件中加上配置\n\n![image-20210901124851022](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901124851022.png)\n\n\n\n然后访问\n\n![image-20210901125242970](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901125242970.png)\n\n这里索引 才开始理解的话 就把它当成一个数据库\n\n\n\n## kibana下载安装\n\n启动 bin下bat\n\n![image-20210901152432828](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901152432828.png)\n\n![image-20210901152651355](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901152651355.png)\n\n以后操作都在这写\n\n汉化！\n\n修改配置即可\n\n![image-20210901153001376](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901153001376.png)\n\n\n\n## ES核心概念\n\n### 概述\n\n集群、节点、索引、类型、文档、分片、映射是什么？\n\n1.索引\n\n2.字段类型（mapping）\n\n3.文档\n\n![image-20210901153524585](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901153524585.png)\n\n一切皆是json\n\n### **物理设计**\n\nelasticsearch在后台把每个索引划分成多个分片，每片分片可以在集群的不同服务器间迁移\n\n\n\n### **文档**\n\n![image-20210901153930053](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901153930053.png)\n\n\n\n### **类型**\n\n![image-20210901154117970](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901154117970.png)\n\n\n\n### **索引**\n\n![image-20210901154218434](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901154218434.png)\n\n\n\n### 倒排索引\n\nelasticsearch使用一种成为倒排索引的结构，采用Lucene倒排索引作为底层。这种结构适用于快速的全文搜索，一个索引由文档中所有不重复的列表构成，对于每一个词，都有一个包含它的文档列表。\n\n![image-20211216142159148](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20211216142159148.png)\n\n![image-20211216142414601](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20211216142414601.png)\n\n\n\n## IK分词器插件\n\n![image-20210901155109102](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901155109102.png)\n\n如果plugins目录下没有 建议去下载并解压 我这里是默认就有一个ik插件的\n\n![image-20210901155350770](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901155350770.png)\n\n![image-20210901155456552](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901155456552.png)\n\n\n\n最少切分 ik_smart\n\n![image-20210901160121662](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901160121662.png)\n\n\n\n最细粒度划分 ik_max_word 穷尽词库的可能！\n\n![image-20210901160150802](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901160150802.png)\n\n\n\n**这里你会有疑问 他是按照什么依据来判定是否构成一个词？存在字典 应该可以改 可以把自己的词加到字典中**\n\n\n\n如果是自己自定义添加的ik 好像有 我这个默认就有的 没看到配置文件\n\n![image-20210901160714138](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901160714138.png)\n\n自定义 需要创建.dic文件\n\n![image-20210901160938676](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901160938676.png)\n\n\n\n然后在配置文件中添加你刚才建的dic\n\n![image-20210901161254920](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210901161254920.png)\n\n## RESTful风格以及使用\n\n![image-20210902105301874](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902105301874.png)\n\n## 关于索引的基本操作\n\n#### 创建一个索引\n\n```\nPUT /索引名/类型名/文档id\n{\n\t请求体\n}\n```\n\n![image-20210902110339025](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902110339025.png)\n\n![image-20210902110402345](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902110402345.png)\n\n\n\n#### 类型\n\n![image-20210902110528324](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902110528324.png)\n\n#### Field datatypes（官方对类型及类型映射的解释）\n\nEach field has a data `type` which can be:\n\n- a simple type like [`text`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/text.html), [`keyword`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/keyword.html), [`date`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/date.html), [`long`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/number.html), [`double`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/number.html), [`boolean`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/boolean.html) or [`ip`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/ip.html).\n- a type which supports the hierarchical nature of JSON such as [`object`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/object.html) or [`nested`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/nested.html).\n- or a specialised type like [`geo_point`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/geo-point.html), [`geo_shape`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/geo-shape.html), or [`completion`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/search-suggesters-completion.html).\n\nIt is often useful to index the same field in different ways for different purposes. For instance, a `string` field could be [indexed](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/mapping-index.html) as a `text` field for full-text search, and as a `keyword` field for sorting or aggregations. Alternatively, you could index a string field with the [`standard` analyzer](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/analysis-standard-analyzer.html), the [`english`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/analysis-lang-analyzer.html#english-analyzer) analyzer, and the [`french` analyzer](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/analysis-lang-analyzer.html#french-analyzer).\n\nThis is the purpose of *multi-fields*. Most datatypes support multi-fields via the [`fields`](https://www.elastic.co/guide/en/elasticsearch/reference/6.0/multi-fields.html) parameter.\n\n#### 指定字段类型\n\nA mapping could be specified when creating an index, as follows:\n\n```console\nPUT my_index \n{\n  \"mappings\": {\n    \"doc\": { \n      \"properties\": { \n        \"title\":    { \"type\": \"text\"  }, \n        \"name\":     { \"type\": \"text\"  }, \n        \"age\":      { \"type\": \"integer\" },  \n        \"created\":  {\n          \"type\":   \"date\", \n          \"format\": \"strict_date_optional_time||epoch_millis\"\n        }\n      }\n    }\n  }\n}\n```\n\n![image-20210902111241544](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902111241544.png)\n\n这里就是创建映射规则，也就是说如果以后由name的值就是text类型\n\n\n\n#### 使用默认类型 _doc\n\n```\nPUT /test3/_doc/1\n{\n  \"name\": \"我无敌\",\n  \"age\": 13,\n  \"birth\": \"1998-09-17\"\n}//这里_doc就是指定默认类型\n```\n\n![image-20210902112117729](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902112117729.png)\n\n#### 修改\n\n曾经\n\nPUT 版本号增加\n\n![image-20210902112718238](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902112718238.png)\n\n现在\n\nPUT\n\nPOST \n\n![image-20210902113308183](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902113308183.png)\n\n![image-20210902113329930](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902113329930.png)\n\n\n\n#### 删除索引\n\n```\nDELETE\n```\n\n如果要删除文档就用RESTful风格请求来删除即可\n\n## 一些命令之类的吧\n\n```\nGET _cat/health //查看健康情况\n\nGET _cat/indices?v //查看索引信息\n\n等等\n```\n\n## 关于文档的基本操作\n\n### 基本操作\n\n#### 添加数据\n\nPUT\n\n![image-20210902150701139](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902150701139.png)\n\n\n\n#### 获取数据\n\nGET\n\n![image-20210902150807827](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902150807827.png)\n\n\n\n#### 更新数据\n\nPUT\n\n区别一个需要全部重新赋值 如果只是改一个值就不方便\n\nPOST\n\n![image-20210902151058613](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902151058613.png)\n\n\n\n#### 简单的搜索\n\nGET\n\n![image-20210902151355320](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902151355320.png)\n\n\n\n![image-20210902151839877](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902151839877.png)\n\n这个score 分数越高匹配度越高\n\n#### 复杂的查询 （排序 分页 高亮 模糊查询）\n\n![image-20210902152036305](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902152036305.png)\n\n\n\nHits这个在java中会是个对象map\n\n![image-20210902152444930](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902152444930.png)\n\n**这一个json格式都能在java中以map的形式体现出来**\n\n\n\n##### _source 结果过滤\n\n这里如果只想要查出来显示想要的字段 （这里体现只要name和desc而不要age）\n\n\n\n![image-20210902152845363](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902152845363.png)\n\n##### 排序\n\n![image-20210902153106388](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902153106388.png)\n\n\n\n##### 分页\n\n![image-20210902153242340](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902153242340.png)\n\n\n\n\n\n##### bool 布尔值条件查询\n\n这里用到了must（and)\n\n还有should（or）\n\n![image-20210902153715766](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902153715766.png)\n\n还存在非\n\nmust_not\n\n##### 过滤\n\n![image-20210902154224098](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902154224098.png)\n\n这里 range 范围 \n\nage范围\n\ngt 表示大于\n\ngte 表示大于等于\n\nlt 表示小于\n\nlte表示小于等于\n\n\n\n##### 匹配多个条件\n\n![image-20210902154615839](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902154615839.png)\n\n\n\n##### 精确查询\n\ntrem查询是直接通过倒排索引指定的词条进行精确的查询\n\n![image-20210902154908396](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902154908396.png)\n\nmatch 会使用分词器\n\n![image-20210902154923978](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902154923978.png)\n\n\n\n##### 两个类型 text,keyword\n\n这里理解 就是keyword不存在分词 无法被拆分，\n\n在检索的时候 如果条件属性的类型是keyword 就无法进行模糊查询\n\n![image-20210902160231604](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902160231604.png)\n\n\n\n\n\n##### 高亮查询\n\n![image-20210902160917322](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902160917322.png)\n\n还可以自定义高亮样式\n\n![image-20210902161138654](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210902161138654.png)\n\n\n\n## SpringBoot集成\n\n首先看官方文档啦\n\n![image-20210903101255730](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903101255730.png)\n\n**这里需要保证导入的依赖和es版本一致 因为由于SpringBoot版本问题会导致默认导入的es的版本和你下的es的版本不同**\n\n![image-20210903103023404](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903103023404.png)\n\n卧槽这里怎么实现的。。。\n\n```\n//先注入吧\n@Configuration\npublic class ElasticSearchClientConfig {\n    @Bean\n    public RestHighLevelClient setRestClient(){\n        RestHighLevelClient client = new RestHighLevelClient(\n                RestClient.builder(\n                        new HttpHost(\"127.0.0.1\", 9200, \"http\")));\n\n        return client;\n    }\n}\n```\n\n源码部分 一言难尽 版本差了一点 源码分布就天差地别...\n\n不过还是老套路 \n\n![image-20210903105926215](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903105926215.png)\n\n这下面去找罢了\n\n\n\n### 创建索引\n\n```\n@Test\nvoid contextLoads() throws IOException {\n    //索引创建请求\n    CreateIndexRequest request = new CreateIndexRequest(\"kuang_index\");\n    //执行请求\n    CreateIndexResponse response = client.indices().create(request, RequestOptions.DEFAULT);\n    System.out.println(response);\n}\n```\n\n![image-20210903110606796](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903110606796.png)\n\n![image-20210903110625586](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903110625586.png)\n\n成功创建索引\n\n\n\n\n\n### 获取以及判断索引\n\n先判断索引是否存在\n\n```\n@Test\nvoid getExistIndex() throws IOException {\n\n    GetIndexRequest request = new GetIndexRequest(\"kuang_index\");\n    boolean b = client.indices().exists(request,RequestOptions.DEFAULT);\n    System.out.println(b);\n}\n```\n\n```\n@Test\nvoid getExistIndex() throws IOException {\n\n    GetIndexRequest request = new GetIndexRequest(\"kuang_index\");\n    boolean b = client.indices().exists(request,RequestOptions.DEFAULT);\n    System.out.println(b);\n    if(b == true){\n        GetIndexResponse response = client.indices().get(request,RequestOptions.DEFAULT);\n        System.out.println(response);\n    }else{\n        System.out.println(\"索引存在\");\n    }\n\n}\n```\n\n\n\n### 删除索引\n\n```\n@Test\nvoid deleteExistIndex() throws IOException{\n    DeleteIndexRequest request = new DeleteIndexRequest(\"kuang_index\");\n    AcknowledgedResponse response = client.indices().delete(request,RequestOptions.DEFAULT);\n    System.out.println(response);\n}\n```\n\n\n\n### 添加文档\n\n```\n//测试添加文档\n@Test\nvoid testAddDocument() throws IOException {\n    //创建对象\n    User user = new User(\"张三\",3,\"法外狂徒\");\n    //创建请求\n    IndexRequest request = new IndexRequest(\"kuang_index\");\n    //规则 PUT /kuang_index/_doc/1\n    request.id(\"1\");\n    request.timeout(TimeValue.timeValueSeconds(1));\n    request.source(JSON.toJSONString(user), XContentType.JSON);\n\n    //客户端发送请求\n    IndexResponse response =  client.index(request,RequestOptions.DEFAULT);\n    System.out.println(response.toString());\n    System.out.println(response.status());\n}\n```\n\n![image-20210903113515670](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903113515670.png)\n\n\n\n\n\n### 获取文档\n\n这里有个对照\n\n```\n@Test\nvoid testGetDocument() throws IOException {\n    GetRequest request = new GetRequest(\"kuang_index\",\"1\");\n    //不获取返回的_source的上下文\n    request.fetchSourceContext(new FetchSourceContext(false));\n    request.storedFields(\"_none_\");\n    if(client.exists(request,RequestOptions.DEFAULT)){\n        GetResponse response = client.get(request,RequestOptions.DEFAULT);\n        System.out.println(response.toString());\n    }\n}\n```\n\n![image-20210903114320162](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903114320162.png)\n\n\n\n\n\n```\n   @Test\n    void testGetDocument() throws IOException {\n        GetRequest request = new GetRequest(\"kuang_index\",\"1\");\n        //不获取返回的_source的上下文\n//        request.fetchSourceContext(new FetchSourceContext(false));\n//        request.storedFields(\"_none_\");\n        if(client.exists(request,RequestOptions.DEFAULT)){\n            GetResponse response = client.get(request,RequestOptions.DEFAULT);\n            System.out.println(response.toString());\n            System.out.println(response.getSource());\n        }\n    }\n```\n\n![image-20210903114509427](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903114509427.png)\n\n\n\n### 更新文档\n\n```\n@Test\nvoid updateDocument() throws IOException {\n    UpdateRequest request = new UpdateRequest(\"kuang_index\",\"1\");\n    User user = new User(\"狂神说java\",12,\"我无敌\");\n    request.doc(JSON.toJSONString(user),XContentType.JSON);\n\n    UpdateResponse response = client.update(request,RequestOptions.DEFAULT);\n    System.out.println(response.status());\n\n\n}\n```\n\n\n\n\n\n### 删除文档\n\n```\n@Test\nvoid deleteDocument() throws IOException{\n    DeleteRequest request = new DeleteRequest(\"kuang_index\",\"1\");\n    DeleteResponse response = client.delete(request,RequestOptions.DEFAULT);\n}\n```\n\n\n\n\n\n### 批量操作文档\n\n```\n/**\n * 批量添加文档\n */\n@Test\nvoid testBulkRequest() throws IOException {\n    BulkRequest request = new BulkRequest();\n    request.timeout(\"10s\");\n\n    ArrayList<User> users = new ArrayList<>();\n    users.add(new User(\"王一\",10,\"测试\"));\n    users.add(new User(\"王二\",9,\"测试\"));\n    users.add(new User(\"王三\",11,\"测试\"));\n    users.add(new User(\"王四\",7,\"测试\"));\n    users.add(new User(\"王五\",15,\"测试\"));\n    //这里是添加\n    for(int i = 0 ; i < users.size() ; i++){\n        request.add(new IndexRequest(\"kuang_index\").id(\"\" + (i+1)).source(JSON.toJSONString(users.get(i)),XContentType.JSON));\n    }\n    //        //批量更新\n\t//        request.add(new UpdateRequest(\"kuang_index\",\"1\").doc(\"\"));\n\t//        //批量删除\n\t//        request.add(new DeleteRequest());\n    BulkResponse response = client.bulk(request,RequestOptions.DEFAULT);\n    System.out.println(response.status());\n\n}\n```\n\n\n\n### 搜索\n\n**这里提示 term和match查询 一个是精确匹配 也就是说不会拆分词 而match会拆 例如 无敌先生 term就只找无敌先生这一个连贯的词 而·match则会拆分为**\n\n**无敌 / 先生 两个词来进行匹配**\n\n\n\n```\n@Test\nvoid testSearch() throws IOException{\n    SearchRequest request = new SearchRequest(\"kuang_index\");\n    //构建查询条件\n    SearchSourceBuilder builder = new SearchSourceBuilder();\n\n    //构建高亮\n    builder.highlighter();\n\n    //设置查询条件（这里用的是QueryBuilders 快速创建一个精确查询）\n    TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"age\",\"7\");\n\t//        QueryBuilders.matchQuery();\n\t//        QueryBuilders.matchAllQuery();\n\n    builder.query(termQueryBuilder);\n\n    request.source(builder);\n\n    SearchResponse response = client.search(request,RequestOptions.DEFAULT);\n\n    System.out.println(response.getHits());\n\n    //这里你会发现如果有中文就没有结果 这里我换成age试了一下才有结果\n    for(SearchHit documentFields : response.getHits().getHits()){\n        System.out.println(documentFields.getSourceAsString());\n    }\n}\n```\n\n\n\n## 实战\n\n### 创建项目\n\n![image-20210903142650016](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903142650016.png)\n\n\n\n![image-20210903142704362](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903142704362.png)\n\n### 爬虫\n\n爬取数据：（获取请求返回的页面信息，筛选出数据）\n\n这里使用的是java中的 jsoup\n\n![image-20210903151124368](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210903151124368.png)\n\n这里再获取图片时 有点小问题 怎么说呢 这里图片采用了延迟加载 而真正存储图片的路径是data-lazy-img\n\n![image-20210903152232054](C:%5CUsers%5Cwcy%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210903152232054.png)\n\n```\n@Test\nvoid contextLoads() throws IOException {\n    String url = \"https://search.jd.com/Search?keyword=java\";\n    //解析网页(Jsoup 返回Document就是浏览器Document对象)\n    Document document = Jsoup.parse(new URL(url),30000);\n    Element element = document.getElementById(\"J_goodsList\");\n    System.out.println(element.html());\n    //获取所有li标签\n    Elements elements = element.getElementsByTag(\"li\");\n    for(Element el : elements){\n        //这里图片一开始没有 因为有个懒加载机制 （延迟加载）\n        String img = el.getElementsByTag(\"img\").eq(0).attr(\"data-lazy-img\");\n        String price = el.getElementsByClass(\"p-price\").eq(0).text();\n        String title = el.getElementsByClass(\"p-name\").eq(0).text();\n        System.out.println(\"========================\");\n        System.out.println(img);\n        System.out.println(price);\n        System.out.println(title);\n    }\n}\n```\n\n\n\n然后对其进行封装成一个方法\n\n```\npublic static List<Content> parseJD(String keyword) throws IOException {\n    String url = \"https://search.jd.com/Search?keyword=\" + keyword;\n    //解析网页(Jsoup 返回Document就是浏览器Document对象)\n    Document document = Jsoup.parse(new URL(url),30000);\n    Element element = document.getElementById(\"J_goodsList\");\n    //获取所有li标签\n    Elements elements = element.getElementsByTag(\"li\");\n    List<Content> contents = new ArrayList<Content>();\n\n    for(Element el : elements){\n        //这里图片一开始没有 因为有个懒加载机制 （延迟加载）\n        String img = el.getElementsByTag(\"img\").eq(0).attr(\"data-lazy-img\");\n        String price = el.getElementsByClass(\"p-price\").eq(0).text();\n        String title = el.getElementsByClass(\"p-name\").eq(0).text();\n        contents.add(new Content(title,img,price));\n    }\n    return contents;\n}\n```\n\n\n\n然后就是具体的封装了\n\n这里贴一些主要的代码\n\n```\n@Service\npublic class ContentService {\n\n    @Autowired\n    RestHighLevelClient restHighLevelClient;\n    //获取并解析数据 然后添加到es中\n    public Boolean parseContent(String keyword) throws IOException {\n        List<Content> contentList = HtmlParseUtil.parseJD(keyword);\n\n        //将数据放入es中\n        BulkRequest request = new BulkRequest(\"jd_goods\");\n        request.timeout(\"2m\");\n        for(int i = 0 ; i < contentList.size() ; i++){\n            request.add(new IndexRequest().source(JSON.toJSONString(contentList.get(i)), XContentType.JSON));\n        }\n        BulkResponse response = restHighLevelClient.bulk(request, RequestOptions.DEFAULT);\n        return !response.hasFailures();\n\n    }\n\n    //从es中获取数据 实现搜索\n    public List<Map<String,Object>> searchPage(String keyword,int pageNo,int pageSize) throws IOException {\n        if(pageNo <= 1){\n            pageNo = 1;\n        }\n        SearchRequest searchRequest = new SearchRequest(\"jd_goods\");\n        SearchSourceBuilder builder = new SearchSourceBuilder();\n        \n        //实现高亮\n        HighlightBuilder highlightBuilder = new HighlightBuilder();\n        //这里表示存在多个关键字时不需要都高亮显示\n        highlightBuilder.requireFieldMatch(false);\n        highlightBuilder.field(\"title\");\n        highlightBuilder.preTags(\"<span style='color:red'>\");\n        highlightBuilder.postTags(\"</span>\");\n        builder.highlighter(highlightBuilder);\n        \n        //分页\n       \tbuilder.from(pageNo);\n       \tbuilder.size(pageSize);\n\n        //精确匹配\n        TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"title\",keyword);\n        builder.query(termQueryBuilder);\n\n        //执行搜索\n        searchRequest.source(builder);\n        SearchResponse response = restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);\n\n        List<Map<String,Object>> list = new ArrayList<>();\n        //解析搜索结果\n        for(SearchHit documentFields : response.getHits().getHits()){\n            //普通\n//            list.add(documentFields.getSourceAsMap());\n            //高亮\n            Map<String, HighlightField> highlightFieldMap = documentFields.getHighlightFields();\n            HighlightField title = highlightFieldMap.get(\"title\");\n            System.out.println(title);\n            Map<String,Object> sourceAsMap = documentFields.getSourceAsMap();//原来的结果\n            //使用高亮来替换\n            if(title != null){\n\n                Text[] fragments = title.fragments();\n                String n_title = \"\";\n                for(Text text : fragments){\n                    n_title += text;\n                }\n                sourceAsMap.put(\"title\",n_title);\n            }\n            list.add(sourceAsMap);\n        }\n        return list;\n\n    }\n\n\n}\n```\n\n\n\n\n\n\n\n# 谷粒商城篇补充与应用学习\n\n## 1.基本概念\n\n### \t1）.索引\n\n​\t\t动词解释：相当于MySQL中的insert\n\n​\t\t名词解释：相当于MySQL的数据库（database）\n\n### \t2）.类型\n\n​\t\t在index(索引)中，可以定义一个或多个类型。\n\n​\t\t类似于MySQL中的表（table）；\n\n​\t\t（这里结合之前狂神说的理解，简单理解为一种表结构的制定，有点这个意思，虽然说es的字段的类型可以不用确认，但如果能先构造结构也是好的，就如MySQL的建表一样。）\n\n​\t\t\n\n### \t3）.文档\n\n​\t\t\t保存在某个索引下，某种类型的一个数据，文档是**JSON格式**的，Document就像是MySQL中某个表中的数据\n\n​\t\t\t（简单解释就是一条条具体的记录、数据）\n\n\n\n### \t4）.倒排索引\n\n​\t\t\t说白了就是额外维护一张文档列表存储 一种关系吧，里面的数据能够说明检索的词存在于哪些文档，这样可以过滤掉一些非必要的检索操作\n\n​\t\t![image-20211216142836513](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20211216142836513.png)\n\n\n\n接下来请转战谷粒商城的笔记...\n\n","tags":["ElasticSearch"],"categories":["框架"]},{"title":"JVM调优参数","url":"/2022/03/19/JVM调优参数/","content":"\n# JVM调优参数\n\n引用地址：[JVM参数使用手册 - SegmentFault 思否](https://segmentfault.com/a/1190000010603813)\n\n**Xms**\n英文解释：`Initial heap size(in bytes)`\n中文释义：`堆区初始值`\n使用方法：`-Xms2g` 或 `-XX:InitialHeapSize=2048m`\n\n**Xmx**\n英文解释：`Maximum heap size(in bytes)`\n中文释义：`堆区最大值`\n使用方法：`-Xmx2g` 或 `-XX:MaxHeapSize=2048m`\n\n**Xmn**\n英文解释：`Maximum new generation size(in bytes)`\n中文释义：`新生代最大值`\n使用方法：`-Xmn512m` 或 `-XX:MaxNewSize=512m`\n\n**PermSize**(JDK1.8以后已废弃)\n英文解释：`Initial size of permanent generation(in bytes)`\n中文释义：`永久代初始大小`\n使用方法：`-XX:PermSize=128m`\n\n**MaxPermSize**(JDK1.8以后已废弃)\n英文解释：`Maximum size of permanent generation(in bytes)`\n中文释义：`永久代最大值`\n使用方法：`-XX:MaxPermSize=256m`\n\n**MetaspaceSize**(JDK1.8以后用于替换PermSize)\n英文解释：`Initial size of Metaspaces (in bytes)`\n中文释义：`元数据区初始大小`\n使用方法：`-XX:MetaspaceSize=128m`\n\n**MaxMetaspaceSize**(JDK1.8以后用于替换MaxPermSize)\n英文解释：`Maximum size of Metaspaces (in bytes)`\n中文释义：`元数据区最大值`\n使用方法：`-XX:MaxMetaspaceSize=256m`\n\n**Xss**\n英文解释：`Thread Stack Size(in Kbytes)`\n中文释义：`线程栈最大值`\n使用方法：`-Xss256k` 或 `-XX:ThreadStackSize=256k`\n\n**MaxDirectMemorySize**\n英文解释：`Maximum total size of NIO direct-buffer allocations`\n中文释义：`最大直接内存（堆外）大小`\n使用方法：`-XX:MaxDirectMemorySize=256m`\n\n\n\n## GC策略相关\n\n> 通过这些参数可以对JVM的GC性能进行调优\n\n**NewRatio**\n英文解释：`Ratio of old/new generation sizes`\n中文释义：`老年代和新生代的比值`\n使用方法：`-XX:NewRatio=2`\n使用经验：假如设为2，则表示老年代最大内存占堆最大内存的2/3，新生代则为1/3。如果设置了Xmn或者NewSize/MaxNewSize，那么NewRatio配置无效\n\n**SurvivorRatio**\n英文解释：`Rato of eden/survivor space size`\n中文释义：`新生代中eden区和survivor区的比值`\n使用方法：`-XX:SurvivorRatio=6`\n使用经验：假如设为6，则表示每个survivor区跟eden区的比值为1:6,每个survivor区占新生代的八分之一\n\n**PretenureSizeThreshold**\n英文解释：`Maximum size in bytes of objects allocated in DefNew generation;zero means no maximum`\n中文释义：`可以在新生代直接分配的对象最大值，0表示没有最大值`\n使用方法：`-XX:PretenureSizeThreshold=1000000`\n使用经验：设置该参数，可以使大于这个值的对象直接在老年代分配，避免在Eden区和Survivor区发生大量的内存复制，该参数只对Serial和ParNew收集器有效，Parallel Scavenge并不认识该参数\n\n**MaxTenuringThreshold**\n英文解释：`Maximum value fo tenuring threshold`\n中文释义：`年轻代最大年龄`\n使用方法：`-XX:MaxTenuringThreshold=10`\n使用经验：每个对象在坚持过一次Minor GC之后，年龄就增加1，当超过这个参数值时就进入老年代，最大支持15\n\n**UseSerialGC**\n英文解释：`Use the Serial garbage collector`\n中文释义：`年轻代使用Serial垃圾收集器`\n使用方法：\n开启 `-XX:+UseSerialGC`\n使用经验：不推荐使用，性能太差，老年代将会使用SerialOld垃圾收集器\n\n**UseParNewGC**\n英文解释：`Use parallel threads in the new generation`\n中文释义：`年轻代使用ParNew垃圾收集器`\n使用方法：\n开启 `-XX:+UseParNewGC`\n\n**ParallelGCThreads**\n英文解释：`Number of parallel threads parallel gc will use`\n中文释义：`并行执行gc的线程数`\n使用方法：`-XX:ParallelGCThreads=16`\n\n**UseParallelGC**\n英文解释：`Use the Parallel Scavenge garbage collector`\n中文释义：`年轻代使用Parallel Scavenge垃圾收集器`\n使用方法：\n开启 `-XX:+UseParallelGC`\n使用经验：Linux下1.6,1.7,1.8默认开启，老年代将会使用SerialOld垃圾收集器\n\n**UseParallelOldGC**\n英文解释：`Use the Parallel Old garbage collector`\n中文释义：`年轻代使用Parallel Scavenge收集器`\n使用方法：\n开启 `-XX:+UseParallelOldGC`\n使用经验：老年代将会使用Parallel Old收集器\n\n**UseConcMarkSweepGC**\n英文解释：`Use Concurrent Mark-Sweep GC in the old generation`\n中文释义：`老年代使用CMS收集器（如果出现\"Concurrent Mode Failure\"，会使用SerialOld收集器）`\n使用方法：\n开启 `-XX:+UseConcMarkSweepGC`\n使用经验：年轻代将会使用ParNew收集器\n\n**CMSInitiatingOccupancyFraction**\n英文解释：`Percentage CMS generation occupancy to start a CMS collection cycle. A negative value means that CMSTriggerRatio is used`\n中文释义：`触发执行CMS回收的当前年代区内存占用的百分比，负值表示使用CMSTriggerRatio设置的值`\n使用方法：`-XX:CMSInitiatingOccupancyFraction=75`\n使用经验：该参数需配合UseCMSInitiatingOccupancyOnly一起使用\n\n**UseCMSInitiatingOccupancyOnly**\n英文解释：`Only use occupancy as a criterion for staring a CMS collection`\n中文释义：`只根据占用情况作为开始执行CMS收集的标准，默认关闭`\n使用方法：\n开启 `-XX:+UseCMSInitiatingOccupancyOnly`\n\n**UseCMSCompactAtFullCollection**\n英文解释：`Use Mark-Sweep-Compact algorithm at full collections`\n中文释义：`使用CMS执行Full GC时对内存进行压缩，默认关闭`\n使用方法：\n开启 `-XX:+UseCMSCompactAtFullCollection`\n\n**CMSFullGCsBeforeCompaction**\n英文解释：`Number of CMS full collection done before compaction if > 0`\n中文释义：`多少次FGC后进行内存压缩`\n使用方法：`-XX:CMSFullGCsBeforeCompaction=1`\n\n**CMSClassUnloadingEnabled**\n英文解释：`Whether class unloading enabled when using CMS GC`\n中文释义：`当使用CMS GC时是否启用类卸载功能，默认关闭`\n使用方法：\n开启 `-XX:+CMSClassUnloadingEnabled`\n\n**CMSParallelRemarkEnabled**\n英文解释：`Whether parallel remark enabled (only if ParNewGC)`\n中文释义：`是否启用并行标记（仅限于ParNewGC），默认关闭`\n使用方法：\n开启 `-XX:+CMSParallelRemarkEnabled`\n\n**UseG1GC**\n英文解释：`Use the Garbage-First garbage collector`\n中文释义：`使用G1垃圾收集器`\n使用方法：\n开启 `-XX:+UseG1GC`\n\n**MaxGCPauseMillis**\n英文解释：`Adaptive size policy maximum GC pause time goal in millisecond, or (G1 Only) the maximum GC time per MMU time slice`\n中文释义：`自适应大小策略的最大GC暂停时间目标（以毫秒为单位），或（仅G1）每个MMU时间片的最大GC时间`\n使用方法：`-XX:MaxGCPauseMillis=200`\n\n**DisableExplicitGC**\n英文解释：`Ignore calls to System.gc()`\n中文释义：`禁用System.gc()触发FullGC`\n使用方法：\n开启 `-XX:+DisableExplicitGC`\nPS:不建议开启，如果开启了这个参数可能会导致堆外内存无法及时回收造成内存溢出\n\n## GC日志相关\n\n> 通过这些参数可以对JVM的GC日志输出进行配置，方便分析\n\n**Xloggc**\n英文解释：`GC log file`\n中文释义：`GC日志文件路径`\n使用方法：`-Xloggc:/data/gclog/gc.log`\n\n**UseGCLogFileRotation**\n英文解释：`Rotate gclog files(for long running applications). It requires -Xloggc:<filename>`\n中文释义：`滚动GC日志文件，须配置Xloggc`\n使用方法：\n开启 `-XX:+UseGCLogFileRotation`\n\n**NumberOfGCLogFiles**\n英文解释：`Number of gclog files in rotation(default:0,no rotation)`\n中文释义：`滚动GC日志文件数，默认0，不滚动`\n使用方法：`-XX:NumberOfGCLogFiles=4`\n\n**GCLogFileSize**\n英文解释：`GC log file size,requires UseGCLogFileRotation. Set to 0 to only trigger rotation via jcmd`\n中文释义：`GC文件滚动大小，需配置UseGCLogFileRotation，设置为0表示仅通过jcmd命令触发`\n使用方法：`-XX:GCLogFileSize=100k`\n\n**PrintGCDetails**\n英文解释：`Print more details at garbage collection`\n中文释义：`GC时打印更多详细信息，默认关闭`\n使用方法：\n开启 `-XX:+PrintGCDetails`\n可以通过`jinfo -flag [+|-]PrintGCDetails <pid>` 或 `jinfo -flag PrintGCDetails=<value> <pid>` 来动态开启或设置值\n\n**PrintGCDateStamps**\n英文解释：`Print date stamps at garbage collection`\n中文释义：`GC时打印时间戳信息，默认关闭`\n使用方法：\n开启 `-XX:+PrintGCDateStamps`\n可以通过`jinfo -flag [+|-]PrintGCDateStamps <pid>` 或 `jinfo -flag PrintGCDateStamps=<value> <pid>` 来动态开启或设置值\n\n**PrintTenuringDistribution**\n英文解释：`Print tenuring age information`\n中文释义：`打印存活实例年龄信息，默认关闭`\n使用方法：\n开启 `-XX:+PrintTenuringDistribution`\n\n**PrintGCApplicationStoppedTime**\n英文解释：`Print the time of application has been stopped`\n中文释义：`打印应用暂停时间，默认关闭`\n使用方法：\n开启 `-XX:+PrintGCApplicationStoppedTime`\n\n**PrintHeapAtGC**\n英文解释：`Print heap layout before and after each GC`\n中文释义：`GC前后打印堆区使用信息，默认关闭`\n使用方法：\n开启 `-XX:+PrintHeapAtGC`","tags":["JVM"],"categories":["运维"]},{"title":"Docker学习","url":"/2022/03/16/Docker学习/","content":"\n# Docker学习\n\n[TOC]\n\n思想来源于集装箱\n\n镜像、隔离\n\n容器化技术 ->节省资源\n\n用于解决不同电脑上可能会无法运行项目的问题，你可能会发现在你电脑上能够运行的项目，放在其他电脑上就可能会无法运行。就算能运行也会让你去配置环境很麻烦。为了解决这个麻烦，大佬们想到了，我把项目和环境一起打包发到其他电脑，让他带着自身的环境跑。例如：以前只需要发送jar包或war包，而现在你需要发送的是 jar+mysql+redis+ES的集合体 相当于另一台电脑不用配置拿来直接运行也能成功。同时这种还是隔离的 也就是说存在多个，都在自己的环境上运行\n\n这里涉及到了虚拟化技术以及容器化技术 传统虚拟机 和 docker 一个是虚拟出整个计算机 而另一个则是虚拟出核心应用\n\n![image-20210615101211422](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210615101211422.png)\n\n\n\n![image-20210615101337685](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210615101337685.png)\n\n## 在服务器上安装docker\n\n### 1.卸载旧的版本  \n\n```\nyum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-engine\n```\n\n### 2.需要的安装包\n\n```\nyum install -y yum-utils\n```\n\n### 3.设置镜像的仓库 默认是国外的\n\n```\nyum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo\n```\n\n```\nyum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n```\n\n### **4.**更新yum软件包索引 \n\n```\nyum makecache fast\n```\n\n### 5.安装doker相关的簇 docker-ce 社区 ee企业版\n\n```\nyum install docker-ce docker-ce-cli containerd.io\n```\n\n### 6.启动docker\n\n```\nsystemctl start docker\n```\n\n### 7.测试hello-word镜像\n\n```\ndocker run hello-world\n```\n\n### 8.卸载docker环境\n\nUninstall Docker Engine\n\n1. Uninstall the Docker Engine, CLI, and Containerd packages:\n\n   ```\n   $ sudo yum remove docker-ce docker-ce-cli containerd.io\n   ```\n\n2. Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes:\n\n   ```\n   $ sudo rm -rf /var/lib/docker\n   $ sudo rm -rf /var/lib/containerd\n   ```\n\nYou must delete any edited configuration files manually.\n\n\n\n## docker命令\n\n列出本地镜像docker images\n\n进入rabbitmq容器docker exec -it 容器名 /bin/bash\n\n退出容器exit\n\n查看运行的容器 docker ps\n\n重启容器 docker restart 容器ID\n\n```\n//在PowerShell中\ndocker inspect --format='{{.Name}} - {{range .[NetworkSettings.Networks](http://networksettings.networks/)}}{{.IPAddress}}{{end}}' $(docker ps -aq)\n```\n\n\n\n### **Docker常用命令**1\n\n容器停止：docker stop \n\n容器名称启动容器：docker start \n\n容器名称删除容器：docker rm \n\n容器名称删除镜像：docker rmi \n\n镜像名称查看运行的所有容器：docker ps\n\n查看所有容器：docker ps -a\n\n容器复制文件到物理机：docker cp 容器名称:容器目录 物理机目录\n\n物理机复制文件到容器：docker cp 物理机目录 容器名称:容器目录\n\n### 帮助命令\n\ndocker version #显示版本信息\n\ndocker info #显示docker的系统信息，包括镜像和容器的数量\n\ndocker 命令 --help #万能帮助命令\n\n#### 帮助文档地址\n\n[Reference documentation | Docker Documentation](https://docs.docker.com/reference/)\n\n### 镜像命令\n\n##### docker images 查看所有本地的主机上的镜像\n\n```\ndocker images #查看所有镜像\ndocker images -a #列出所有镜像\ndocker images -q #只列出镜像id\n```\n\n##### docker search 搜索镜像\n\ndocker search\n\n```\n# docker search --help \n\nUsage:  docker search [OPTIONS] TERM\n\nSearch the Docker Hub for images\n#这里发现可以通过过滤条件来进行搜索镜像\nOptions:\n  -f, --filter filter   Filter output based on conditions provided\n      --format string   Pretty-print search using a Go template\n      --limit int       Max number of search results (default 25)\n      --no-trunc        Don't truncate output\n\ndocker search mysql --filter=STARS=3000\n```\n\n##### docker pull 下载/拉去镜像\n\n```\n#下载镜像 docker pull 镜像名[:tag]\n#例如 docker pull mysql:5.7\n# docker pull mysql\nUsing default tag: latest #不写tag 默认latest 最新\n\nlatest: Pulling from library/mysql\n69692152171a: Pull complete #分层下载，docker image的核心 联合文件系统\n1651b0be3df3: Pull complete \n951da7386bc8: Pull complete \n0f86c95aa242: Pull complete \n37ba2d8bd4fe: Pull complete \n6d278bb05e94: Pull complete \n497efbd93a3e: Pull complete \nf7fddf10c2c2: Pull complete \n16415d159dfb: Pull complete \n0e530ffc6b73: Pull complete \nb0a4a1a77178: Pull complete \ncd90f92aa9ef: Pull complete \nDigest: sha256:d50098d7fcb25b1fcb24e2d3247cae3fc55815d64fec640dc395840f8fa80969 #签名\nStatus: Downloaded newer image for mysql:latest\ndocker.io/library/mysql:latest #真实地址\n\n```\n\n##### docker rmi 删除镜像\n\n```\ndocker rmi -f 容器id #删除指定的镜像\ndocker rmi -f 容器id 容器id 容器id #删除多个镜像\ndocker rmi -f $(docker images -aq) #一次性删除所有镜像\n```\n\n\n\n### 容器命令\n\n说明：有了镜像才可以创建容器，linux，下载一个centos镜像来测试学习\n\n```\ndocker pull centos\n```\n\n##### 新建容器并启动\n\n```\ndocker run [可选参数] image\n\n#可选参数说明\n--name=\"Name\"  容器名字 区分容器\n-d\t\t\t\t后台方式运行\n-it\t\t\t使用交互方式运行，进入容器查看内容\n-p\t\t\t\t指定容器的端口 -p 8080\n\t\t-p ip:主机端口：容器端口\n\t\t-p 主机端口：容器端口（常用）\n\t\t-p 容器端口\n\t\t容器端口\n-P\t\t\t\t随机指定端口\n\n#测试，启动并进入容器\ndocker run -it centos /bin/bash\n\n#从容器退出回主机\nexit\n```\n\n##### 列出所有运行中的容器\n\n```\ndocker ps #列出当前正在运行的容器\ndocker ps -a #列出当前正在运行的容器，带出历史运行过的容器\n-n=? #显示最近创建的容器\n-q #只显示容器的编号\n```\n\n##### 退出容器\n\n```\nexit #退出并停止\nCtrl + P + Q #容器不停止退出\n```\n\n##### 删除容器\n\n```\ndocker rm 容器id #删除指定容器 无法删除 正在运行的删除\n-f 强制删除\ndocker rm -f $(docker ps -aq) #删除所有正在运行的容器\ndocker ps -a -q|xargs docker rm #删除所有容器\n```\n\n##### 启动和停止容器的操作\n\n```\ndocker start 容器id\ndocker restart 容器id\ndocker stop 容器id\ndocker kill 容器id\n```\n\n\n\n##### 开机自启动容器\n\n```\ndocker update xxxx --restart=always\n```\n\n\n\n### 常用的其他命令\n\n#### 后台启动容器\n\n```\ndocker run -d centos\n#问题发现docker ps 发现centos停止 没有启动啊\n#常见的坑 docker 容器启动后台运行 就必须要有一个前台进程，如果docker没有发现前台 就会自动停止\n#nginx 容器启动后 发现自己没有提供服务 就会立刻停止 就没有程序了\n```\n\n#### 查看日志\n\n```\ndocker logs -f -t --tail 数量 容器id\n#-f -t 可以合并成 -tf\ndocker logs -tf --tail 数量 容器id\ndocker logs -tf --tail 10 e57567db3d69\n#退出日志查看\nctrl + c\n```\n\n#### 查看容器中进程的信息\n\n```\ndocker top 容器id\n```\n\n#### 查看镜像元数据\n\n```\ndocker image inspect 镜像名\n```\n\n```\ndocker inspect 容器id\n```\n\n![image-20210615131322464](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210615131322464.png)\n\n#### 进入当前正在运行的容器\n\n```\n#我们通常容器都是使用后台方式运行的，需要进入容器，修改一些配置\ndocker exec -it 容器id /bin/bash\n\ndocker attach 容器id \n#docker exec 进入容器后开启一个新的终端 然后进行操作\n#docker attach 进入容器正在执行的终端\n```\n\n#### 从容器内拷贝文件到主机上\n\n```\ndocker cp 容器id:容器内路径 目的的主机路径\n```\n\n\n\n## 底层原理\n\n![image-20210614161706676](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210614161706676.png)\n\n![image-20210614161807275](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210614161807275.png)\n\n![image-20210614161909705](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210614161909705.png)\n\n\n\n## 小练习\n\n### 1.安装nginx\n\n```\n1.docker search nginx #先查找镜像（这种一般都有官方镜像）\n\n2.docker pull nginx #拉取镜像\n\n3.docker run -d --name nginx01 -p 3304:80 nginx #运行 \n```\n\n这里 -p命令要多讲一句 3304 和 80 因为docker中是容器与容器之间隔离 而每个容器相当于一个小的liunx环境 而我们是在linux上使用docker里面的容器 而3304 80 就相当于映射关系 ，容器暴露出来的是80 而外面的linux暴露给用户的是3304 访问3304 就相当于访问这个容器的80端口\n\n![image-20210621093031956](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621093031956.png)\n\n\n\n### 2.安装Tomcat\n\n```\n1.docker search tomcat #先查找tomcat镜像\n\n2.docker pull tomcat #拉取tomcat 最新镜像 可以指定版本号\n\n3.docker run -d --name tomcat01 -p 3305:8080 tomcat #启动tomcat\n```\n\n这里你会发现虽然启动 但是访问 3305 却是404 因为这里下载的镜像中 tomcat是阉割版的 webapps里面没有任何东西 此时我们就需要进入容器 将webapps.dist中的东西复制到webapps中就有界面了\n\n```\ncp -r webapps.dist/* webapps\n```\n\n\n\n### 3.安装ElasticSearch\n\n```\n1.docker search elasticsearch #先查找es\n\n2.docker pull elasticsearch #拉去es\n\n3.docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms64m -Xmx 512m\" elasticsearch:tag\n#这里启动es 但是你会发现占用很多 这里可以给参数设置占用\n\n```\n\n\n\n\n\n## 可视化\n\nportainer(先用这个)\n\n```\ndocker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce\n```\n\nRancher(CI/CD再用)\n\n\n\n什么是portainer？\n\nDocker图形化界面管理工具！提供一个后台供我们操作\n\n```\ndocker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce\n```\n\n![image-20210621101624416](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621101624416.png)\n\n![image-20210621101706750](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621101706750.png)\n\n![image-20210621101745842](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621101745842.png)\n\n平时不会用 玩玩即可\n\n\n\n## Docker镜像讲解\n\n### 镜像是什么\n\n镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件\n\n如何获取镜像：\n1.远程仓库下载\n\n2.朋友拷贝\n\n3.自己制作 DockerFile\n\n### Docker镜像加载原理\n\nUnionFS(联合文件系统)\n\n我们下载的时候看到的一层一层的就是这个！\n\n![image-20210621103719585](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621103719585.png)\n\n![image-20210621103804494](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621103804494.png)\n\n### 分层理解\n\n分层的镜像\n\n当我们去下载一个镜像，注意观察下载的日志输出， 可以看到时一层一层的在下载\n\n![image-20210621104148017](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621104148017.png)\n\n\n\n![image-20210621105014067](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621105014067.png)\n\n![image-20210621105041126](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621105041126.png)\n\n![image-20210621105104213](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621105104213.png)\n\n![image-20210621104942787](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621104942787.png)\n\n\n\n![image-20210621104727300](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621104727300.png)\n\n![image-20210621104903011](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621104903011.png)\n\n如何提交自己的镜像\n\n### Commit镜像\n\ndocker commit\n\n```\nUsage:  docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n\nCreate a new image from a container's changes\n\nOptions:\n  -a, --author string    Author (e.g., \"John Hannibal Smith <hannibal@a-team.com>\")\n  -c, --change list      Apply Dockerfile instruction to the created image\n  -m, --message string   Commit message\n  -p, --pause            Pause container during commit (default true)\n\n\ndocker commit -m=\"描述\" -a=\"作者\" 容器id/镜像名 标签tag\n```\n\n实战测试：\n\n拿tomcat为例，之前讲过由于是阉割版，所以webapps下没有文件，而我将webapps.dist下的文件拷贝过去了，这就是一个操作，相当于在之前的基础上加了一层\n\n![image-20210621111324594](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621111324594.png)\n\n然后就可以提交\n\n```\ndocker commit -m=\"add webapps app\" -a=\"wangchengyang\" 246c13894f24 tomcat02\n```\n\n![image-20210621111520668](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210621111520668.png)\n\n\n\n## 容器数据卷\n\n### 什么是容器数据卷？\n\ndocker的概念\n\n将应用和环境打包成一个镜像\n\n如果有许多数据都在容器中，删除容器后，数据就会丢失。例如：mysql容器中保存sql数据 删了的话就会丢失------>此时我们需要数据可以持久化（持久化安装docker的本地/虚拟机上）\n\ndocker容器间也需要有一个数据同步的技术 docker产生的数据同步到本地！\n\n卷技术 目录的挂载 将容器中的目录 挂载到linux下\n\n![image-20210622091901509](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622091901509.png)\n\n小结：容器数据的持久化和同步，以及容器间数据的共享（例如：多个mysql容器，设置同一个持久化目录 到时候读取都是在同一个目录下的文件读取，从而实现数据共享）\n\n### 使用数据卷\n\n方式一：1.使用命令来挂载\n\n```\ndocker run -it -v 主机目录：容器目录 镜像名 /bin/bash #启动设置卷并进入\ndocker run -it -v /home/ceshi:/home centos /bin/bash\n```\n\n使用 docker inspect 容器id 查看容器具体信息 发现有个挂载\n\n![image-20210622093028857](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622093028857.png)\n\n有双向绑定那味了\n\n![image-20210622093550889](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622093550889.png)\n\n\n\n再来测试：\n\n1.停止容器\n\n2.在主机上修改文件\n\n3。重启容器\n\n4.容器内的数据依旧是同步的\n\n![image-20210622094541989](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622094541989.png)\n\n这里看出 主机的修改也能应用到容器中，这是一个双向绑定\n\n\n\n\n\n### 实战：安装MySQL\n\nMySQL的数据持久化的问题！\n\n```\ndocker search mysql\ndocker pull mysql\n#官方启动\ndocker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag\n\n我们自己启动\n-d 后台运行\n-p 端口映射\n-v 数据卷挂载\n-e 环境参数配置\ndocker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql\n```\n\n然后通过数据库可视化工具 添加数据库 test 这里就可以看出新增了test\n\n![image-20210622101847631](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622101847631.png)\n\n\n\n### 具名挂载和匿名挂载\n\n```\n#匿名挂载\n-v 容器内路径\n-P 容器自己指定端口映射 大p和小p的区别\ndocker run -d -P -v /etc/nginx --name nginx01 nginx\n\n#查看所有的volume（卷）的情况\ndocker volume ls\n\n#具名挂载\ndocker run -d -P -v juming-nginx:/etc/nginx --name nginx02 nginx\n```\n\n![image-20210622103055810](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622103055810.png)\n\n```\n#查看卷的具体信息\ndocker volume inspect 卷名\ndocker volume inspect juming-nginx\n```\n\n![image-20210622103253209](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622103253209.png)\n\n所有没有指定目录的卷 都是在 /var/lib/docker/volumes/xxxxx/_data\n\n```\n-v 容器内路径  #匿名挂载\n-v 卷名:容器内路径 \n-v 主机路径:容器内路径 #指定路径挂载\n```\n\n拓展：\n\n```\n#通过 -v 容器内路径:ro rw 改变读写权限\nro readonly #只读\nrw readwrite #可读可写\n\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:ro nginx\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:rw nginx\n```\n\n### 初识DockerFile\n\n用于创建镜像 这里通过创建镜像的同时挂载卷 这里是通过写脚本来创建镜像所以卷的挂载也在这个脚本中！\n\nDockerFile就是用来构建docker镜像的构建文件！命令脚本\n\n通过脚本可以生成一个镜像，镜像是一层一层的，所以脚本是一个一个的命令\n\n![image-20210622113506479](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622113506479.png)\n\n```\n#生成镜像 （切记 最后有个 .）\ndocker build -f /home/docker-test-volume/dockerfile1 -t wangchengyang/centos:1.0 . \n```\n\n然后通过进项启动容器(这里我是以centos为基础 搭建的镜像)\n\n```\ndocker run -it 镜像名 /bin/bash\nls -l查看目录 你会发现有volume1 和 volume2这两个文件\n```\n\n![image-20210622114037299](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622114037299.png)\n\n接下来我们去在volume1中创建个文件 container.txt\n\n退出容器并查看容器详细信息 （去看挂载卷目录）\n\n![image-20210622114228368](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622114228368.png)\n\n和明显没指定主机路径 就会在/var/lib/docker/volumes 下面 去看一下是否有container.txt\n\n![image-20210622114434462](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622114434462.png)\n\n总结：这种方法就是在构建镜像的时候就挂载数据卷 当然这里是一个匿名卷\n\n而我们也可以手动通过 -v 来挂载\n\n### 数据卷容器\n\n![image-20210622114733997](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210622114733997.png)\n\n```\n--volumes-from\n```\n\n其实这里老师讲的有问题 这里我们使用的是刚才自己的镜像 而这个镜像都是挂载到了本地也就是所以就算创建三个容器但这个三个容器挂载的数据卷本机上的路径都是一样的，而这样看来就已经实现了数据共享（因为双向绑定） 而这个--volumes-from则更多地类似于指出关系；也许就正常的而言，在都没挂载卷的情况下使用这个命令会是单纯容器之间的数据共享\n\n## DockerFile\n\n先来看看什么是DockerFile，其实这是构建镜像的脚本文件\n\n构建步骤：\n\n​\t1.编写一个DockerFile文件\n\n​\t2.docker build 构建镜像\n\n​\t3.docker run 运行镜像\n\n​\t4.docker push 发布镜像（DockerHub、阿里云）\n\n### DockerFile构建过程\n\n基础知识：\n\n​\t1.每个保留关键字（指令）都是必须是大写字母\n\n​\t2.执行从上到下顺序执行\n\n​\t3.#表示注解\n\n​\t4.每一个指令都会创建提交一个新的镜像层，并提交\n\n![image-20210624112411623](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624112411623.png)\n\n\n\n### DockerFile指令\n\nFROM\t\t\t基础镜像 一切从这里开始\n\nMAINTAINER\t\t\t镜像是谁些的，姓名+邮箱 wangchengyang<2837288678@qq.com>\n\nRUN\t\t\t\t镜像构建时需要执行的命令\n\nADD\t\t\t\t添加内容 比如说我基础是centos要加一个tomcat\n\nWORKDIR\t\t镜像工作目录\n\nVOLUME\t\t\t卷 挂载的目录\n\nEXPOSE\t\t\t暴露端口\n\nCMD\t\t\t\t\t指定容器启动时候要运行的命令 命令会覆盖 如本来CMD ls\n\nENTRYPOINT\t\t指定这个容器启动的时候要运行的命令 可以追加命令\n\nONBUILD\t\t\t当构建一个被继承DockerFile 这个时候就会触发ONBUILD指令，该配置指定当所创建的镜像作为其他新建镜像的基础镜像时所执行的指令。\n\nCOPY\t\t\t\t\t类似ADD 将文件拷贝到镜像中\n\nENV                      构建时候的环境配置（例如环境变量的配置）\n\n### 实战\n\n#### 构建自己的centos\n\n先编写DockerFile\n\n![image-20210624113644384](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624113644384.png)\n\n然后通过\n\ndocker build -f mydockerfile-centos -t mycentos:1.0 .\n\n来构建自己的镜像\n\n最后启动 你会发现安装了vim和net-tools 可以使用vim和ifconfig命令了\n\n\n\ndocker history 镜像id 可以查看镜像是如何安装\n\n![image-20210624114020576](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624114020576.png)\n\n\n\n#### 构建tomcat\n\n1.准备镜像文件 tomcat压缩包 jdk的压缩包\n\n![image-20210624114950718](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624114950718.png)\n\n2.编写dockerfile文件 官方命名Dockerfile build会自动寻找这个文件，就不需要-f指定\n\n![image-20210624125642278](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624125642278.png)\n\n```\nFROM centos\nMAINTAINER wangchengyang<2837288678@qq.com>\n\nCOPY readme.txt /usr/local/readme.txt\n\nADD jdk-8u291-linux-x64.tar.gz /usr/local/\nADD apache-tomcat-9.0.48.tar.gz /usr/local/\n\nRUN yum -y install vim\n\nENV MYPATH /usr/local\nWORKDIR /usr/local\n\n\nENV JAVA_HOME /usr/local/jdk1.8.0_291\nENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nENV CATALINA_HOME /usr/local/apache-tomcat-9.0.48\nENV CATALINA_BASH /usr/local/apache-tomcat-9.0.48\nENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin\n\nEXPOSE 8080\n\nCMD /usr/local/apache-tomcat-9.0.48/bin/startup.sh && tail -F /usr/local/apache-tomcat-9.0.48/bin/logs/catalina.out\n\n```\n\n3.构建镜像\n\n![image-20210624125613776](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624125613776.png)\n\n![image-20210624125709347](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624125709347.png)\n\n4.启动镜像\n\n```\ndocker run -d -p 9090:8080 --name wangchengyangtomcat -v /tomcat/test:/usr/local/apache-tomcat-9.0.48/webapps/test -v /tomcat/tomcatlogs:/usr/local/apache-tomcat-9.0.48/logs diytomcat\n```\n\n5.访问测试\n\ncurl localhost:9090\n\n\n\n6.发布项目（由于做了卷挂载，我们直接在本地编写项目就可以发布）\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee\n                      http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\"\n         metadata-complete=\"true\">\n</web-app>\n```\n\n```\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<body>\n<h2>Hello World!</h2>\n \n</body>\n</html>\n```\n\n这里遇到一个坑 我将index.jsp放入了test/WEB-INF下 但因为只是个简单配置WEB-INF下只放web.xml就够了 index.jsp 应该和WEB-INF同级\n\n\n\n### 发布自己的镜像\n\nDockerHub\n\n1.地址[Docker Hub](https://hub.docker.com/) 要有自己的账号\n\n2.确定账号可以登录\n\n3.在服务器上提交自己的镜像\n\n现在服务器上登录docker\n\n```\n[root@izuf66wqqqhhr0ktipcmxfz test]# docker login --help\n\nUsage:  docker login [OPTIONS] [SERVER]\n\nLog in to a Docker registry.\nIf no server is specified, the default is defined by the daemon.\n\nOptions:\n  -p, --password string   Password\n      --password-stdin    Take the password from stdin\n  -u, --username string   Username\n\n```\n\n![image-20210624143302197](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624143302197.png)\n\n上传（这让我想到了git的推拉） docker push\n\n#### DockerHub上传：\n\n这里要注意 镜像的tag一定要符合要求 如果不符合需要改\n\n通过\n\n```\ndocker tag 镜像id docker账号名/新名:版本号\ndocker tag 9e4e904b2a17 wangchengyang/mytomcat:1.0\n```\n\n![image-20210624144948399](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624144948399.png)\n\n#### 阿里云上传：\n\n##### 1.登录阿里云\n\n##### 2.找到容器镜像服务\n\n##### 3.创建命名空间\n\n![image-20210624145907587](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624145907587.png)\n\n##### 4.创建容器镜像\n\n![image-20210624150020004](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624150020004.png)\n\n##### 5.上传阿里云具体操作方法\n\n###### 1.登录阿里云Docker Registry\n\n```\n$ docker login --username=xxxxx registry.cn-shanghai.aliyuncs.com\n```\n\n用于登录的用户名为阿里云账号全名，密码为开通服务时设置的密码。\n\n您可以在访问凭证页面修改凭证密码。\n\n###### 2. 从Registry中拉取镜像\n\n```\n$ docker pull registry.cn-shanghai.aliyuncs.com/wangchengyang-study/wangchengyang-test:[镜像版本号]\n```\n\n###### 3. 将镜像推送到Registry\n\n```\n$ docker login --username=xxxxx registry.cn-shanghai.aliyuncs.com$ docker tag [ImageId] registry.cn-shanghai.aliyuncs.com/wangchengyang-study/wangchengyang-test:[镜像版本号]$ docker push registry.cn-shanghai.aliyuncs.com/wangchengyang-study/wangchengyang-test:[镜像版本号]\n```\n\n请根据实际镜像信息替换示例中的[ImageId]和[镜像版本号]参数。\n\n###### 4. 选择合适的镜像仓库地址\n\n从ECS推送镜像时，可以选择使用镜像仓库内网地址。推送速度将得到提升并且将不会损耗您的公网流量。\n\n如果您使用的机器位于VPC网络，请使用 registry-vpc.cn-shanghai.aliyuncs.com 作为Registry的域名登录。\n\n###### 5. 示例\n\n使用\"docker tag\"命令重命名镜像，并将它通过专有网络地址推送至Registry。\n\n```\n$ docker imagesREPOSITORY                                                         TAG                 IMAGE ID            CREATED             VIRTUAL SIZEregistry.aliyuncs.com/acs/agent                                    0.7-dfb6816         37bb9c63c8b2        7 days ago          37.89 MB$ docker tag 37bb9c63c8b2 registry-vpc.cn-shanghai.aliyuncs.com/acs/agent:0.7-dfb6816\n```\n\n使用 \"docker push\" 命令将该镜像推送至远程。\n\n```\n$ docker push registry-vpc.cn-shanghai.aliyuncs.com/acs/agent:0.7-dfb6816\n```\n\n### 小结\n\n![image-20210624151810382](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624151810382.png)\n\n![image-20210624152143319](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210624152143319.png)\n\n## Docker网络（铺垫 容器编排 集群部署 ）\n\n我去，笔记又没保存就退出了，啊，心态有一点小炸，不过考验自己学习的时候到了！！！！\n\n### 原理\n\n```\nip addr #这个命令用来查看容器ip 后面要用\n```\n\n首先我们 使用 ip addr\n\n![image-20210626124321945](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626124321945.png)\n\n而如果你启动一个容器就会出现变化\n\n![image-20210626124459841](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626124459841.png)\n\n然后进入容器内部查看ip信息\n\n![image-20210626124542737](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626124542737.png)\n\n你会发现这里面的东西是互相对应了，所以说这里就涉及到evth-pair技术\n\nevth-pair就是一对的虚拟设备接口，它们都是成对出现的，一端连着协议，一端彼此相连\n\n正因为这个特性，evth-pair从当了一个桥梁，连接各种虚拟网络\n\n![image-20210626124900837](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626124900837.png)\n\n结论：tomcat01 和tomcat02 都是一个公用的路由器 docker0\n\n所有容器在不指定网络的情况下（后面会讲 -net）都是docker0路由的，它会分配容器一个默认ip\n\n![image-20210626125114823](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626125114823.png)\n\n以上很容易看出这是使用了桥接模式\n\nDocker中的所有网络接口都是虚拟的，虚拟的转发效率高！\n\n只要容器删除，对应网桥一对就没了\n\n### --link\n\n这里思考的问题时能否通过容器名直接访问另一个容器，为什么需要呢？因为可能存在服务名没换但ip换了的情况\n\n不能直接访问但是你可以通过 --link来指定\n\n```\ndocker run -d -P --name tomcat02 --link tomcat01 tomcat\n```\n\n而这里是单向绑定的 为什么？可以通过进入容器查看hosts文件看出\n\n这样绑定后hosts文件中多出一个映射来实现访问\n\n```\ndocker exec -it tomcat02 cat /etc/hosts\n```\n\n![image-20210626131311651](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626131311651.png)\n\ntomcat01 则没有 所以是单向的\n\n但是后面是不建议使用 --link的 可能过时 或者是不满足需求吧\n\n后来我们更多的是选择自定义一个网络\n\ndocker0的问题：他不支持容器名连接访问\n\n\n\n### 自定义网络\n\n容器互联： --link/定义网络\n\n```\ndocker network --help   #这个命令常用\nUsage:  docker network COMMAND\n\nManage networks\n\nCommands:\n  connect     Connect a container to a network\n  create      Create a network\n  disconnect  Disconnect a container from a network\n  inspect     Display detailed information on one or more networks\n  ls          List networks\n  prune       Remove all unused networks\n  rm          Remove one or more networks\n\n```\n\n![image-20210626131724384](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626131724384.png)\n\n#### 网络模式：\n\nbridge：桥接 docker 大桥（默认）\n\nnone：不配置网络\n\nhost：和宿主机共享网络\n\ncontainer：容器网络连通（用的少）\n\n#### 测试\n\n```\n#之前我们直接启动的命令其实是带了默认的参数 --net的 后面我们可以自己指定\ndocker run -d -P --name tomcat01 --net bridge tomcat\n#这里bridge就是docker0\n\n#docker0特点，默认，域名不能访问，--link可以打通连接！\n\n#我们可以自定义个网络\ndocker network create --help\nUsage:  docker network create [OPTIONS] NETWORK\n\nCreate a network\n\nOptions:\n      --attachable           Enable manual container attachment\n      --aux-address map      Auxiliary IPv4 or IPv6 addresses used by Network driver (default map[])\n      --config-from string   The network from which to copy the configuration\n      --config-only          Create a configuration only network\n  -d, --driver string        Driver to manage the Network (default \"bridge\")\n      --gateway strings      IPv4 or IPv6 Gateway for the master subnet\n      --ingress              Create swarm routing-mesh network\n      --internal             Restrict external access to the network\n      --ip-range strings     Allocate container ip from a sub-range\n      --ipam-driver string   IP Address Management Driver (default \"default\")\n      --ipam-opt map         Set IPAM driver specific options (default map[])\n      --ipv6                 Enable IPv6 networking\n      --label list           Set metadata on a network\n  -o, --opt map              Set driver specific options (default map[])\n      --scope string         Control the network's scope\n      --subnet strings       Subnet in CIDR format that represents a network segment\n\ndocker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet\n```\n\n![image-20210626132731398](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626132731398.png)\n\n这里可以查看网络详细信息\n\n```\ndocker network inspect mynet\n\n\n[\n    {\n        \"Name\": \"mynet\",\n        \"Id\": \"66915e474ee9fe650a70cf37d9eed18551a55e2df11eb52d9a9649b4684c511d\",\n        \"Created\": \"2021-06-26T13:26:59.003948015+08:00\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": {},\n            \"Config\": [\n                {\n                    \"Subnet\": \"192.168.0.0/16\",\n                    \"Gateway\": \"192.168.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {},\n        \"Options\": {},\n        \"Labels\": {}\n    }\n]\n\n```\n\n![image-20210626133408027](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626133408027.png)\n\n你会发现通过自定义网络去实现的话能够直接通过容器名进行连接访问\n\n通过 docker network inspect mynet也可一看到详情中已经有了两个容器\n\n![image-20210626133809874](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210626133809874.png)\n\n自定义网络中docker已经帮我们维护好了对应关系，推荐使用自定义网络\n\n\n\n### 网络连通\n\n为什么需要？如果说doccker0中的容器想直接访问在自定义网络中的容器那是不现实的。\n\n可以通过一个命令来实现\n\n```\ndocker network connect\n```\n\n![image-20210627091405958](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210627091405958.png)\n\n```\n#测试打通docker0上的tomcat01和mynet上的tomcat-net-01\n\ndocker network connect mynet tomcat01\n\n#本质一个容器 可以有多个ip地址 既存在于docker0网络下又存在于mynet网络下\n```\n\n![image-20210627091950388](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210627091950388.png)\n\n你会发现mynet下多了个容器映射tomcat01\n\n![image-20210627092118015](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/img/image-20210627092118015.png)\n\n总结：如果需要跨网络访问，就需要docker network connect\n\n\n\n### Redis集群部署实战\n\n先创建网卡\n\n```\ndocker network create redis --subnet 172.38.0.0/16\n```\n\n首先这里重点是通过shell脚本来创建启动服务\n\n```\nfor port in $(seq 1 6);\\\ndo \\\nmkdir -p /mydata/redis/node-${port}/conf\ntouch /mydata/redis/node-${port}/conf/redis.conf\ncat <<EOF>/mydata/redis/node-${port}/conf/redis/conf\nport 6379\nbind 0.0.0.0\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\ncluster-announce-ip 172.38.0.1${port}\ncluster-announce-port 6379\ncluster-announce-bus-port 16379\nappendonly yes #aof\nEOF   #结束cat命令\ndone\n```\n\n启动容器\n\n```\ndocker run -p 637${port}:6379 -p 1637${port}:13679 --name redis-${port} \\\n-v /mydata/redis/node-${port}/data:/data \\\n-v /mydata/redis/node-${port}/redis.conf:/etc/redis/redis.conf \\\n-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\n```\n\n```\n#通过脚本创建\n[root@izuf66wqqqhhr0ktipcmxfz conf]# for port in $(seq 1 6)\n> \\\n> do\n> docker run -p 637${port}:6379 -p 1637${port}:13679 --name redis-${port} \\\n> -v /mydata/redis/node-${port}/data:/data \\\n> -v /mydata/redis/node-${port}/redis.conf:/etc/redis/redis.conf \\\n> -d --net redis --ip 172.38.0.11 redis:5.0.9-alpine 3.11 redis-server /etc/redis/redis.conf\n> done\n\n\n#或者自己一条一条启动\ndocker run -p 6371:6379 -p 16371:16379 --name redis-1 \\\n-v /mydata/redis/node-1/data:/data \\\n-v /mydata/redis/node-1/conf/redis.conf:/etc/redis/redis.conf \\\n-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\n\ndocker run -p 6372:6379 -p 16372:16379 --name redis-2 \\\n-v /mydata/redis/node-2/data:/data \\\n-v /mydata/redis/node-2/conf/redis.conf:/etc/redis/redis.conf \\\n-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\n\ndocker run -p 6373:6379 -p 16373:16379 --name redis-3 \\\n-v /mydata/redis/node-3/data:/data \\\n-v /mydata/redis/node-3/conf/redis.conf:/etc/redis/redis.conf \\\n-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\n\ndocker run -p 6374:6379 -p 16374:16379 --name redis-4 \\\n-v /mydata/redis/node-4/data:/data \\\n-v /mydata/redis/node-4/conf/redis.conf:/etc/redis/redis.conf \\\n-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\n\ndocker run -p 6375:6379 -p 16375:16379 --name redis-5 \\\n-v /mydata/redis/node-5/data:/data \\\n-v /mydata/redis/node-5/conf/redis.conf:/etc/redis/redis.conf \\\n-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\n\ndocker run -p 6376:6379 -p 16376:16379 --name redis-6 \\\n-v /mydata/redis/node-6/data:/data \\\n-v /mydata/redis/node-6/conf/redis.conf:/etc/redis/redis.conf \\\n-d --net redis --ip 172.38.0.11 redis:5.0.9-alpine3.11 redis-server /etc/redis/redis.conf\n```\n\n然后通过进入一个redis目录\n\n```\ndocker exec -it redis-1 /bin/sh #这里不是bash了\n```\n\n然后就是通过\n\n```\nredis-cli --cluster create host:port host:port .. --cluster-replicas 1 \n#通过集群模式搭建集群\n```\n\n进入redis集群\n\n```\nredis-cli -c\ncluster nodes #查看节点\n```\n\n\n\n### SpringBoot项目部署\n\n准备个小demo hello的web项目 打包->idea有打包工具\n\n然后就是写Dockerfile可以在IDEA中写 最后都要复制到服务器中\n\n```\nFROM java:8\n\nCOPY *.jar /app.jar\n\nCMD [\"--server.port=8080\"]\n\nEXPOSE 8080\nENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]\n\n```\n\n然后就是通过\n\n```\ndocker build -t wcy666\n```\n\n然后启动\n\n```\ndocker run -d -P --name wcy-web wcy666\n```\n\n测试\n\n```\ncurl localhost:xxxx\n```\n\n\n\n\n\n## ","tags":["docker"],"categories":["运维"]},{"title":"java基础知识","url":"/2022/02/21/JAVA基础知识/","content":"\n\n# JAVA基础知识\n\n## 容器/集合\n\n### HashMap\n\n![捕获](https://gitee.com/buxiaoxin2333/pic-bed/raw/master/202202151615866.PNG)\n\n聊到HashMap，我需要想到HashMao的那张结构图 最早的HashMap是数组加链表的形式存在的。\n\n（散列）-> 将任意长度的输入转化为固定长度的输出\n\n链表存在着查询差，但插入简单的特点，所以前面几个版本是由segment（桶）这个概念的，不过现在都是在达到临界点后将链表转化为红黑树。（链表长度达到8或者是数组长度大于64时）\n\n基本的几个值\n\n```\n\t/**\n     * The default initial capacity - MUST be a power of two.\n     */\n    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16\n\n    /**\n     * The maximum capacity, used if a higher value is implicitly specified\n     * by either of the constructors with arguments.\n     * MUST be a power of two <= 1<<30.\n     */\n    static final int MAXIMUM_CAPACITY = 1 << 30;\n\n    /**\n     * The load factor used when none specified in constructor.\n     */\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n    /**\n     * The bin count threshold for using a tree rather than list for a\n     * bin.  Bins are converted to trees when adding an element to a\n     * bin with at least this many nodes. The value must be greater\n     * than 2 and should be at least 8 to mesh with assumptions in\n     * tree removal about conversion back to plain bins upon\n     * shrinkage.\n     */\n    static final int TREEIFY_THRESHOLD = 8;\n\n    /**\n     * The bin count threshold for untreeifying a (split) bin during a\n     * resize operation. Should be less than TREEIFY_THRESHOLD, and at\n     * most 6 to mesh with shrinkage detection under removal.\n     */\n    static final int UNTREEIFY_THRESHOLD = 6;\n\n    /**\n     * The smallest table capacity for which bins may be treeified.\n     * (Otherwise the table is resized if too many nodes in a bin.)\n     * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts\n     * between resizing and treeification thresholds.\n     */\n    static final int MIN_TREEIFY_CAPACITY = 64;\n```\n\n1.DEFAULT_INITIAL_CAPACITY（初始化容量） 1<<4 也就是16\n\n2.MAXIMUM_CAPACITY（最大的容量） = 1 << 30;\n\n3.DEFAULT_LOAD_FACTOR = 0.75f;（负载因子）具体有啥用 源代码中在说，貌似在扩容中有使用到\n\n4.TREEIFY_THRESHOLD（转化为树的临界点） = 8 也就是说在增加数据时，什么时候将list转化为树（也就是之前讲到的链表达到多少长度时会转化为红黑树）\n\n5.UNTREEIFY_THRESHOLD = 6；（这个有点模糊，我看注释的意思是在不是树的时候重新设置容量大小的操作关键 补充：好像是当你移除节点小于6的时候 红黑树要转化为链表）\n\n6.MIN_TREEIFY_CAPACITY = 64 这个就是当数组长度达到64时就会树化。\n\n\n\n好了基本的常量看完了，就是梦开始的地方了！！！\n\n首先既然有链表，那么就会有节点，这里提供了一个静态内部类\n\n```\nstatic class Node<K,V> implements Map.Entry<K,V> {\n        final int hash;\n        final K key;\n        V value;\n        Node<K,V> next;\n\n        Node(int hash, K key, V value, Node<K,V> next) {\n            this.hash = hash;\n            this.key = key;\n            this.value = value;\n            this.next = next;\n        }\n\n        public final K getKey()        { return key; }\n        public final V getValue()      { return value; }\n        public final String toString() { return key + \"=\" + value; }\n\n        public final int hashCode() {\n            return Objects.hashCode(key) ^ Objects.hashCode(value);\n        }\n\n        public final V setValue(V newValue) {\n            V oldValue = value;\n            value = newValue;\n            return oldValue;\n        }\n\n        public final boolean equals(Object o) {\n            if (o == this)\n                return true;\n            if (o instanceof Map.Entry) {\n                Map.Entry<?,?> e = (Map.Entry<?,?>)o;\n                if (Objects.equals(key, e.getKey()) &&\n                    Objects.equals(value, e.getValue()))\n                    return true;\n            }\n            return false;\n        }\n    }\n```\n\n4个主要的值，计算得到的hash值，key，value以及下一个节点的引用，这就很好地体现了一开始的那个结构\n\n来点有意思的，之前提到过我们是通过散列算法来确定存储的数组下标位置的，这里就是HashMap中的hash计算方式，这个值是先通过hashCode计算出来的值**按位与**他的无符号右移16位来获得\n\n```\nstatic final int hash(Object key) {\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n}\n```\n\n\n\n然后来点简单的get方法\n\n```\npublic V get(Object key) {\n        Node<K,V> e;\n        return (e = getNode(hash(key), key)) == null ? null : e.value;\n    }//这里会去调用getNode方法,是通过key来进行查找\n    \n    \nfinal Node<K,V> getNode(int hash, Object key) {//这里接收的是hash值和key值\n        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;\n        if ((tab = table) != null && (n = tab.length) > 0 &&\n            (first = tab[(n - 1) & hash]) != null) { //这里一堆条件同时也进行了一些赋值操作，其中头节点first会通过hash找到 tab[n-1 & hash] \n            if (first.hash == hash && // always check first node  \n                ((k = first.key) == key || (key != null && key.equals(k))))\n                return first;//这里既然找到了头节点，就好办了，先判断头节点的hash值是否相同，然后是比较key，如果都满足就直接返回\n            if ((e = first.next) != null) {//这里是头节点不满足条件，就接着链表往后找\n                if (first instanceof TreeNode) //这里由于后面会有转化为树的情况，所以在这里要判断是不是树\n                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);//如果是树就走树的查找方法\n                do {//不是树就开始循环遍历链表\n                    if (e.hash == hash &&\n                        ((k = e.key) == key || (key != null && key.equals(k))))\n                        return e;\n                } while ((e = e.next) != null);\n            }\n        }\n        return null;\n}\n```\n\n\n\n上面是获取，接下来就是put方法\n\n```\npublic V put(K key, V value) {\n        return putVal(hash(key), key, value, false, true);\n    }\n    \n    //Params:\n\t//hash – hash for key\n\t//key – the key\n\t//value – the value to put\n\t//onlyIfAbsent – if true, don't change existing value\n\t//evict – if false, the table is in creation mode.\n\t//Returns:\n\t//previous value, or null if none\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) { //还是先来看看传入的参数，我们传入的也只有key value\n        Node<K,V>[] tab; Node<K,V> p; int n, i;\n        if ((tab = table) == null || (n = tab.length) == 0)\n            n = (tab = resize()).length; //这里还是简单的判断和赋值 这里resize方法很重要，后面会讲到\n        if ((p = tab[i = (n - 1) & hash]) == null)\n            tab[i] = newNode(hash, key, value, null);//这里很显然是看数组位置上是否存在头节点，没有就会建一个，将我们传入的直接丢进去\n        else {//这里就是数组位置上已经有一条链表或者树 这个要判断，然后就可以想象这条链表上或树上是否之前存过相同key，有就覆盖，没有就进行尾插\n            Node<K,V> e; K k;\n            if (p.hash == hash &&\n                ((k = p.key) == key || (key != null && key.equals(k))))\n                e = p;//这里先看头节点是否匹配\n            else if (p instanceof TreeNode)\n                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n            else {\n                for (int binCount = 0; ; ++binCount) {\n                    if ((e = p.next) == null) {\n                        p.next = newNode(hash, key, value, null);\n                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                            treeifyBin(tab, hash);\n                        break;\n                    }\n                    if (e.hash == hash &&\n                        ((k = e.key) == key || (key != null && key.equals(k))))\n                        break;\n                    p = e;\n                }\n            }\n            if (e != null) { // existing mapping for key\n                V oldValue = e.value;\n                if (!onlyIfAbsent || oldValue == null)\n                    e.value = value;\n                afterNodeAccess(e);\n                return oldValue;\n            }\n        }\n        ++modCount;//记录着集合的修改次数，也就每次add或者remove它的值都会加1\n        if (++size > threshold)//这里我的理解是为了保证容器的查询效率，通过对数组扩容的方式来保证数组中各个链表不至于太长，而影响查询，而这个threshold会在第一个初始化resize时设置 当然后面还有树化来保证查询效率 双管齐下\n            resize();\n        afterNodeInsertion(evict);\n        return null;\n    }\n```\n\n\n\n来吧，重头戏，resize方法：其实这里以及之前都有个迷糊点啊 这个threshold临界点可能不是很清楚干嘛的 因为之前有treeify零界点，导致我容易搞混淆\n\n我在看了一些东西后突然想到了这个值可不可能是因为链表虽然不需要担心扩容之类的问题，但是在查询上是需要遍历是效率不高的，所以说为了使链表不至于太长，所以说我们选择数组扩容，而这个关键就是threshold，因为你每添加一个节点进去就会 size+1 所以说当size > threshold时，为了保证搜索效率而进行的扩容。\n\n```\nif (++size > threshold)\n            resize();\n```\n\n\n\n```\n\n    /**\n     * The next size value at which to resize (capacity * load factor).\n     *\n     * @serial\n     */\n    // (The javadoc description is true upon serialization.\n    // Additionally, if the table array has not been allocated, this\n    // field holds the initial array capacity, or zero signifying\n    // DEFAULT_INITIAL_CAPACITY.)\n    int threshold;//这里说的是重新设置容量后的大小，等下带入下面看看吧.....\n```\n\n\n\n```\nfinal Node<K,V>[] resize() {\n        Node<K,V>[] oldTab = table;//首先赋值将需要resize的数组放进来，这里可以看出需要扩容的是数组（一看就知道，啰嗦一句）\n        int oldCap = (oldTab == null) ? 0 : oldTab.length;\n        int oldThr = threshold;\n        int newCap, newThr = 0;\n        if (oldCap > 0) { //标识不是一个新的HashMap时扩容，就容量和临界值都扩大两倍\n            if (oldCap >= MAXIMUM_CAPACITY) {\n                threshold = Integer.MAX_VALUE;\n                return oldTab;\n            }\n            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&\n                     oldCap >= DEFAULT_INITIAL_CAPACITY)\n                newThr = oldThr << 1; // double threshold\n        }\n        else if (oldThr > 0) // initial capacity was placed in threshold\n            newCap = oldThr;//这里表示你初始化传入了一个threshold来进行初始化吧，但感觉没啥用\n        else {               // zero initial threshold signifies using defaults\n            newCap = DEFAULT_INITIAL_CAPACITY;\n            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n            //这里一般就是第一个也就是初始化resize会进入的地方来对cap和thr进行初始化\n        }\n        if (newThr == 0) {\n            float ft = (float)newCap * loadFactor;\n            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?\n                      (int)ft : Integer.MAX_VALUE);//这个的场景暂时不明确\n        }\n        threshold = newThr;\n        @SuppressWarnings({\"rawtypes\",\"unchecked\"})\n            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];\n        table = newTab;\n        if (oldTab != null) {\n            for (int j = 0; j < oldCap; ++j) {\n                Node<K,V> e;\n                if ((e = oldTab[j]) != null) {\n                    oldTab[j] = null;\n                    if (e.next == null)\n                        newTab[e.hash & (newCap - 1)] = e;\n                    else if (e instanceof TreeNode)\n                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n                    else { // preserve order\n                        Node<K,V> loHead = null, loTail = null;\n                        Node<K,V> hiHead = null, hiTail = null;\n                        Node<K,V> next;\n                        do {\n                            next = e.next;\n                            if ((e.hash & oldCap) == 0) {\n                                if (loTail == null)\n                                    loHead = e;\n                                else\n                                    loTail.next = e;\n                                loTail = e;\n                            }\n                            else {\n                                if (hiTail == null)\n                                    hiHead = e;\n                                else\n                                    hiTail.next = e;\n                                hiTail = e;\n                            }\n                        } while ((e = next) != null);\n                        if (loTail != null) {\n                            loTail.next = null;\n                            newTab[j] = loHead;\n                        }\n                        if (hiTail != null) {\n                            hiTail.next = null;\n                            newTab[j + oldCap] = hiHead;\n                        }\n                    }\n                }\n            }\n        }\n        return newTab;\n    }\n```\n\n\n\n## 多态\n\n多态是同一个行为具有多个不同表现形式或形态的能力(这个没有同意定义), 关键是分为运行时多态和编译时多态, 运行时多态的体现是在程序运行时确定使用哪一个函数, 比如将子类对象赋值给父类对象, 然后调用某个方法, 而编译时多态是在编译时确定使用哪一个函数, 体现为重载, 在编译时根据参数和返回值类型确定使用哪个函数.","tags":["java"],"categories":["编程"]},{"title":"Linux命令","url":"/2022/02/21/Linux命令/","content":"\n\n\n# Linux命令\n\nuname -r 系统内核版本查看\n\ntar -zxvf 解压命令\n\nwget 下载命令\n\nls -l 查看文件目录 不是1 是L\n\nps -ef|grep redis 查看后台是否启动redis服务\n\nchmod 777 路径/文件 开放读写权限\n\nll 查看当前路径下文件权限\n\ncp 复制备份命令\n\npwd 查看当前路径\n\nlsof -i :端口号 查看端口是否占用\n\nrm -f 文件 删除文件\n\ntouch 文件 创建文件\n\nvim 文件  使用vim文本编辑器\n\nwhereis xxx查看是否有\n\n./文件 表示执行这个文件 例如：./configure\n\ndu -sh 查看当前文件夹大小\n\ndu -h 查看当前文件夹下所有文件 是所有具体的文件"},{"title":"测试一下我的内容","url":"/2022/02/14/hello-world/","content":"---\n\n# 并发\n\n## 特性\n\n原子性\n\n可见性\n\n有序性\n\n## 记录\n\n今天我看到了贴吧中一个贴子，是关于可见性的问题，我看了一下很有意思，自己一开始也不知道为什么\n\n```\npublic class visibilityTest {\n\t//没有加volatile\n    public static Integer flag = 2;\n    public static void main(String[] args) {\n\n        new Thread(()->{\n            System.out.println(\"1号线程启动，执行循环\");\n            while(flag == 2){\n                System.out.println(\"1\");\n            }\n            System.out.println(\"循环结束\");\n        }).start();\n\n        try{\n            Thread.sleep(1000);\n        }catch(InterruptedException e){\n           e.printStackTrace();\n        }\n\n        new Thread(()->{\n            System.out.println(\"二号线程启动\");\n            flag = 3;\n        }).start();\n\n    }\n\n}\n```\n\n以上代码运行你会发现，循环结束了。。。这里问题就在与明明没有保证可见性的东西，为什么线程2修改了变量，线程1很快就获取到了。\n\n这里需要讲到每个线程都有自己的一块工作内存 而实际数据是在主存中，而最后我们会把工作内存的数据更新到主存中。\n\n这里线程2更新数据并保存到了主存，线程1咋知道的。这里一开始我也不清楚，因为一听到可见性就像到volatile，可这也没有啊。\n\n但是通过我的一顿百度，我想我大概是了解了部分真相。\n\n原来 在println中有个操作\n\n```\npublic void println(String x) {\n        synchronized (this) {\n            print(x);\n            newLine();\n        }\n    }\n```\n\n这里会有一个同步代码块，也就是说这里会进行加锁操作\n\n一下是复制的一段\n\nJMM关于synchronized的两条规定：\n\n　　1）线程解锁前，必须把共享变量的最新值刷新到主内存中\n\n　　2）线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新获取最新的值\n\n　　　（注意：加锁与解锁需要是同一把锁）\n\n   通过以上两点，可以看到synchronized能够实现可见性。同时，由于synchronized具有同步锁，所以它也具有原子性\n\n所以说我们在while循环中使用println时，就是在不断清空工作内存中的共享变量的值，然后获取最新值，所以线程2更新后，线程1能够拿到更新后的值"}]